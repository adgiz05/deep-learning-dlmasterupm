{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Deep Learning - Master in Deep Learning of UPM</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE**\n",
    "\n",
    "Antes de empezar debemos instalar PyTorch Lightning, por defecto, esto valdría:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, si te encuentras ejecutando este código en Google Collab, lo mejor será que montes tu drive para tener acceso a los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning\n",
    "import torchmetrics\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATA_PATH = 'data/stocks.csv'\n",
    "SEED = 42\n",
    "seed_everything(seed=SEED) # Fijamos una semilla para reproducibilidad en los experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya sabemos como atacar mediante el uso de Redes Neuronales Recurrentes un problema univariable de series temporales. En este ejercicio práctico subiremos algo el nivel enfrentándonos a un clásico problema de stock prediction. Utilizaremos técnicas similares para predecir el valor futuro de diversas acciones.\n",
    "\n",
    "Nuestra variable objetivo será el precio de cierre de cierta acción en el futuro (Close), sin embargo, ahora tenemos otras variables que representan como ha evolucionado el precio en el transcurso de un día, como son:\n",
    "- Open: en qué precio abrió\n",
    "- Close: en qué precio cerró\n",
    "- High: el valor más alto en el día\n",
    "- Low: el valor más bajo en el día\n",
    "\n",
    "Como ya hemos visto, en series temporales, la misma variable puede ser a la vez inputs y etiquetas, siempre y cuando difieran temporalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df['Name'] == 'AMZN']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87574</th>\n",
       "      <td>03/01/2006</td>\n",
       "      <td>47.47</td>\n",
       "      <td>47.85</td>\n",
       "      <td>46.25</td>\n",
       "      <td>47.58</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87575</th>\n",
       "      <td>04/01/2006</td>\n",
       "      <td>47.48</td>\n",
       "      <td>47.73</td>\n",
       "      <td>46.69</td>\n",
       "      <td>47.25</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87576</th>\n",
       "      <td>05/01/2006</td>\n",
       "      <td>47.16</td>\n",
       "      <td>48.20</td>\n",
       "      <td>47.11</td>\n",
       "      <td>47.65</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87577</th>\n",
       "      <td>06/01/2006</td>\n",
       "      <td>47.97</td>\n",
       "      <td>48.58</td>\n",
       "      <td>47.32</td>\n",
       "      <td>47.87</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87578</th>\n",
       "      <td>09/01/2006</td>\n",
       "      <td>46.55</td>\n",
       "      <td>47.10</td>\n",
       "      <td>46.40</td>\n",
       "      <td>47.08</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date   Open   High    Low  Close  Name\n",
       "87574  03/01/2006  47.47  47.85  46.25  47.58  AMZN\n",
       "87575  04/01/2006  47.48  47.73  46.69  47.25  AMZN\n",
       "87576  05/01/2006  47.16  48.20  47.11  47.65  AMZN\n",
       "87577  06/01/2006  47.97  48.58  47.32  47.87  AMZN\n",
       "87578  09/01/2006  46.55  47.10  46.40  47.08  AMZN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df['Name'] == 'AMZN']\n",
    "\n",
    "df.head() # Imprimamos las primeras filas del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset hay muchas empresas (AMZN, GOOGL, IBM), coged la que consideréis más interesante ([más información](https://www.kaggle.com/datasets/szrlee/stock-time-series-20050101-to-20171231/data))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2006-01-03 00:00:00 to 2017-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_PATH)\n",
    "data = data[data['Name'] == 'AMZN']\n",
    "data = data.drop(columns=['Name'])\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "data.sort_values('Date', inplace=True)\n",
    "print(f\"Date range: {data['Date'].min()} to {data['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye un Dataset que reciba la compañía sobre la que se va a entrenar, el tamaño de ventana y de horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StocksDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, w=10, h=1):\n",
    "        self.data = df.drop(['Date', 'Name'], axis=1).values\n",
    "        self.target = df['Volume'].values\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - (self.w + self.h) + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx:idx+self.w] # [i: i+w)\n",
    "        target = self.target[idx+self.w: idx+self.w+self.h] # [i+w, i+w+h)\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seguir, el siguiente código no debe dar error ninguno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 'AMZN'\n",
    "w = 10\n",
    "h = 3\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df['Name'] == comp]\n",
    "dataset = StocksDataset(df, w=w, h=h)\n",
    "\n",
    "sample = dataset[0]\n",
    "\n",
    "assert len(sample) == 2 # Comprobamos que el dataset devuelve dos elementos\n",
    "assert sample[0].shape == (w, 5) # Comprobamos que las features tienen la forma correcta\n",
    "assert sample[1].shape == (h,) # Comprobamos que el target tiene la forma correcta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos crear el DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesDataModule(pytorch_lightning.LightningDataModule):\n",
    "    def __init__(self, df, comp='AMZN', w=10, h=1, batch_size=16, val_size=0.2, test_size=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        df = df[df['Name'] == comp]\n",
    "        self.train_df, self.val_df, self.test_df = self.sequential_train_val_test_split(df, val_size=val_size, test_size=test_size)\n",
    "        # self.price_scaler, self.volume_scaler = self.normalize()\n",
    "\n",
    "        self.comp = comp\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = StocksDataset(self.train_df, w=self.w, h=self.h)\n",
    "            self.val_dataset = StocksDataset(self.val_df, w=self.w, h=self.h)\n",
    "        elif stage == 'test':\n",
    "            self.test_dataset = StocksDataset(self.test_df, w=self.w, h=self.h)\n",
    "\n",
    "    def sequential_train_val_test_split(self, df, val_size=0.2, test_size=0.2):\n",
    "        # Aseguramos el formate de la fecha y ordenamos por ella\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "        df.sort_values('Date', inplace=True)\n",
    "\n",
    "        # Calculamos los índices para hacer los splits\n",
    "        n = len(df)\n",
    "        train_end = int((1 - val_size - test_size) * n)\n",
    "        val_end = int((1 - test_size) * n)\n",
    "\n",
    "        train = df.iloc[:train_end].copy()\n",
    "        val = df.iloc[train_end:val_end].copy()\n",
    "        test = df.iloc[val_end:].copy()\n",
    "\n",
    "        return train, val, test\n",
    "    \n",
    "    # Tendremos dos scalers, uno para los precios y otro para el volumen ya que son dos magnitudes distintas\n",
    "    def normalize(self):\n",
    "        # Identify columns\n",
    "        price_cols = ['Open', 'High', 'Low', 'Close']\n",
    "        volume_col = ['Volume']\n",
    "\n",
    "        # Non-scaled columns\n",
    "        train_non_scaled = self.train_df[['Date', 'Name']]\n",
    "        val_non_scaled = self.val_df[['Date', 'Name']]\n",
    "        test_non_scaled = self.test_df[['Date', 'Name']]\n",
    "\n",
    "        # Fit scaler for prices\n",
    "        price_scaler = MinMaxScaler()\n",
    "        price_scaler.fit(self.train_df[price_cols])\n",
    "        \n",
    "        # Fit scaler for volume separately\n",
    "        volume_scaler = MinMaxScaler()\n",
    "        volume_scaler.fit(self.train_df[volume_col])\n",
    "\n",
    "        # Scale train\n",
    "        train_prices = price_scaler.transform(self.train_df[price_cols])\n",
    "        train_volume = volume_scaler.transform(self.train_df[volume_col])\n",
    "\n",
    "        # Scale val\n",
    "        val_prices = price_scaler.transform(self.val_df[price_cols])\n",
    "        val_volume = volume_scaler.transform(self.val_df[volume_col])\n",
    "\n",
    "        # Scale test\n",
    "        test_prices = price_scaler.transform(self.test_df[price_cols])\n",
    "        test_volume = volume_scaler.transform(self.test_df[volume_col])\n",
    "\n",
    "        # Reconstruct the DataFrames\n",
    "        scaled_train = pd.DataFrame(train_prices, columns=price_cols, index=self.train_df.index)\n",
    "        scaled_train['Volume'] = train_volume\n",
    "\n",
    "        scaled_val = pd.DataFrame(val_prices, columns=price_cols, index=self.val_df.index)\n",
    "        scaled_val['Volume'] = val_volume\n",
    "\n",
    "        scaled_test = pd.DataFrame(test_prices, columns=price_cols, index=self.test_df.index)\n",
    "        scaled_test['Volume'] = test_volume\n",
    "\n",
    "        self.train_df = pd.concat([train_non_scaled, scaled_train], axis=1)\n",
    "        self.val_df = pd.concat([val_non_scaled, scaled_val], axis=1)\n",
    "        self.test_df = pd.concat([test_non_scaled, scaled_test], axis=1)\n",
    "\n",
    "        # Store scalers if you want to invert transform later\n",
    "        self.price_scaler = price_scaler\n",
    "        self.volume_scaler = volume_scaler\n",
    "\n",
    "        return self.price_scaler, self.volume_scaler\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        features, targets = zip(*batch)\n",
    "\n",
    "        features = np.stack(features, axis=0)  # [batch_size, w, input_size]\n",
    "        targets = np.stack(targets, axis=0)    # [batch_size, h, input_size]\n",
    "\n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        return features, targets\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación creemos nuestro modelo de regresión temporal basado en una RNN. La diferencia con el que hemos aprendido en clase será que este reciba un argumento extra _pooling_[str] que podrá tomar tres valores y actuar en consecuencia:\n",
    "\n",
    "- _pooling_ = \"last\" -> tomará la última salida de la RNN\n",
    "- _pooling_ = \"mean\" -> realizará las medias a lo largo del eje temporal\n",
    "- _pooling_ = \"max\" -> computará el máximo en la dimensión temporal\n",
    "\n",
    "Sea cual sea la dimensión de salida no deberá variar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Regressor model\n",
    "    h[int]: horizonte de predicción\n",
    "    input_size[int]: variables de la serie temporal\n",
    "    hidden_size[int]: tamaño de las capas ocultas de la RNN\n",
    "    num_layers[int]: número de capas de la RNN (si > 1, stacking de células RNN)\n",
    "    batch_first[bool]: si el batch_size es la primera dimensión\n",
    "    p_drop[float]: probabilidad de dropout\n",
    "    pooling[str]: tipo de pooling a realizar sobre las salidas de la RNN\n",
    "    \"\"\"\n",
    "    def __init__(self, h=1, input_size=1, hidden_size=64, num_layers=1, batch_first=True, p_drop=0.0, pooling='last'):\n",
    "        super().__init__()\n",
    "        self.pooling = pooling\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=batch_first, dropout=p_drop)\n",
    "        self.out = nn.Linear(hidden_size, h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs, _ = self.rnn(x) # [batch_size, seq_len, input_size] -> [batch_size, seq_len, hidden_size]\n",
    "        match self.pooling:\n",
    "            case 'last': # Última salida de la RNN\n",
    "                pooled = outputs[:, -1, :]\n",
    "            case 'mean': # Media de las salidas de la RNN\n",
    "                pooled = outputs.mean(dim=1)\n",
    "            case 'max': # Máximo de las salidas de la RNN\n",
    "                pooled = torch.max(outputs, dim=1)\n",
    "\n",
    "        return self.out(pooled) # [batch_size, hidden_size] -> [batch_size, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creemos el LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictor(pytorch_lightning.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() # guardamos la configuración de hiperparámetros\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def compute_batch(self, batch, split='train'):\n",
    "        inputs, targets = batch\n",
    "        output = self(inputs)\n",
    "\n",
    "        preds = output.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        loss = self.criterion(preds, targets)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                f'{split}_loss': loss, \n",
    "            }, \n",
    "            on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.compute_batch(batch, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.compute_batch(batch, 'val')\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.compute_batch(batch, 'test')\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate) # self.parameters() son los parámetros del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio opcional: programar un Callback que una vez acabe el entrenamiento muestre una gráfica (Matplotlib) de forecasting con el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingCallback(pytorch_lightning.Callback):\n",
    "    def on_fit_end(self, trainer, pl_module):\n",
    "        # Obtenemos el datamodule\n",
    "        dm = trainer.datamodule\n",
    "\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        # Iteramos sobre el test_dataloader\n",
    "        with torch.no_grad():\n",
    "            for batch in dm.test_dataloader():\n",
    "                features, targets = batch\n",
    "                # features: [batch_size, seq_len, 1] (o como sea tu input)\n",
    "                # targets: [batch_size, horizon] (o [batch_size] si es un horizonte 1)\n",
    "                \n",
    "                preds = pl_module(features)  # [batch_size, horizon] o [batch_size]\n",
    "                \n",
    "                # Guardamos predicciones y targets\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_targets.append(targets.cpu())\n",
    "\n",
    "                # Concatenamos todos los batch para tener un solo tensor\n",
    "                all_preds = torch.cat(all_preds, dim=0)\n",
    "                all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "                # Si es horizonte 1:\n",
    "                # all_preds: [N], all_targets: [N]\n",
    "                # Si es horizonte > 1, puedes elegir un paso en particular o hacer promedio\n",
    "                # Ej: tomamos el primer paso:\n",
    "                if len(all_preds.shape) > 1:  # horizonte > 1\n",
    "                    all_preds = all_preds[:, 0]\n",
    "                    all_targets = all_targets[:, 0]\n",
    "\n",
    "                all_preds = all_preds.numpy()\n",
    "                all_targets = all_targets.numpy()\n",
    "\n",
    "                # Ahora graficamos\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(all_targets, label='Real')\n",
    "                plt.plot(all_preds, label='Predicción')\n",
    "                plt.title('Comparación de Predicción vs Real (Test)')\n",
    "                plt.xlabel('Índice de muestra')\n",
    "                plt.ylabel('Valor')\n",
    "                plt.legend()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A entrenar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1069877/2103315029.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
      "/tmp/ipykernel_1069877/2103315029.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values('Date', inplace=True)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Missing logger folder: lightning_logs/sales/2024-12-07_13-15-09/metrics\n",
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/adrian/workspace/deep-learning-dlmasterupm/assignments/sequential/session_8/lightning_logs/sales/2024-12-07_13-15-09 exists and is not empty.\n",
      "\n",
      "  | Name      | Type         | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model     | RNNRegressor | 17.7 K | train\n",
      "1 | criterion | MSELoss      | 0      | train\n",
      "---------------------------------------------------\n",
      "17.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 K    Total params\n",
      "0.071     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d7b5065539434fb511caf81409aa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641fc20484664cb68d7610885c7390b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72d0259b2d14de5882caec1a6758b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3857953c8804877bc2eb9f42a8423b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7460cc56a344270b438f52ab56fbeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad7b77d8aca450f86af54af38775027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2963b19faae049f3900e6cc245d7de01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cbc0513ffa45ebbfb00a1d1a200d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a7c4102ed940318922315860eb407b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50143aef8194010a4492249ad779757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ad3e8c5a124a1d9eb09f97c494578d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5258fd57514f41bfc750aea437b9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a82a287bf4440087c31d3b08eecb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c983b7a55f4a4cbd316320da6a9084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181fb03473324754a91cef7b196dbe93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d16472d544f4a29bee3e9c6705045a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e1bf6d4a343678f6b9a42638e5d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/home/adrian/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35305b2b2d14f688349e928ba6b1eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     18337094434816.0      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    18337094434816.0     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parámetros\n",
    "SAVE_DIR = f'lightning_logs/sales/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}'\n",
    "comp = 'AMZN'\n",
    "w = 10\n",
    "h = 3\n",
    "input_size = 5\n",
    "batch_size = 64\n",
    "num_layers = 1\n",
    "hidden_size = 128\n",
    "learning_rate = 1e-3\n",
    "p_drop = 0.2\n",
    "pooling = 'last'\n",
    "\n",
    "# DataModule\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data_module = SalesDataModule(data, comp=comp, w=w, h=h, batch_size=batch_size)\n",
    "\n",
    "# Model \n",
    "model = RNNRegressor(h=h, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, p_drop=p_drop, pooling=pooling)\n",
    "\n",
    "# LightningModule\n",
    "module = StockPredictor(model, learning_rate=learning_rate)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping_callback = pytorch_lightning.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # monitorizamos la pérdida en el conjunto de validación\n",
    "    mode='min', \n",
    "    patience=5, # número de epochs sin mejora antes de parar\n",
    "    verbose=False, # si queremos que muestre mensajes del estado del early stopping \n",
    ")\n",
    "model_checkpoint_callback = pytorch_lightning.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss', # monitorizamos la pérdida en el conjunto de validación\n",
    "    mode='min', # queremos minimizar la pérdida\n",
    "    save_top_k=1, # guardamos solo el mejor modelo\n",
    "    dirpath=SAVE_DIR, # directorio donde se guardan los modelos\n",
    "    filename=f'best_model' # nombre del archivo\n",
    ")\n",
    "\n",
    "# Descomentar en función de si queremos o no el callback de forecasting\n",
    "# forecasting_callback = ForecastingCallback()\n",
    "# callbacks = [early_stopping_callback, model_checkpoint_callback, forecasting_callback]\n",
    "\n",
    "callbacks = [early_stopping_callback, model_checkpoint_callback]\n",
    "\n",
    "# Loggers\n",
    "csv_logger = pytorch_lightning.loggers.CSVLogger(\n",
    "    save_dir=SAVE_DIR,\n",
    "    name='metrics',\n",
    "    version=None\n",
    ")\n",
    "\n",
    "loggers = [csv_logger] # se pueden poner varios loggers (mirar documentación)\n",
    "\n",
    "# Trainer\n",
    "trainer = pytorch_lightning.Trainer(max_epochs=50, accelerator='cpu', callbacks=callbacks, logger=loggers)\n",
    "\n",
    "trainer.fit(module, data_module)\n",
    "results = trainer.test(module, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7423580.573163997, 5924819.223535961)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.train_df['Volume'].mean(), data_module.train_df['Volume'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3529859.554635762, 2400129.892092458)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.val_df['Volume'].mean(), data_module.val_df['Volume'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3860430.7168874172, 1848569.537651131)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.test_df['Volume'].mean(), data_module.test_df['Volume'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Volumen de transacciones'}, xlabel='Date'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAHHCAYAAABQhTneAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7Q0lEQVR4nO3dd1gURx8H8O9R7uhNuqJi710ReyFg12hiNMYeTdEkxhQ1sURTrFGjMTHmTSyJRlNssfcSxY4NGxbsgIr0fjfvH8jKcndw4FEOvp/n4fF2ZnZ3djnufs5OUQghBIiIiIjKCLPirgARERFRUWLwQ0RERGUKgx8iIiIqUxj8EBERUZnC4IeIiIjKFAY/REREVKYw+CEiIqIyhcEPERERlSkMfoiIiKhMYfBDVAjCw8OhUCiwYsWK4q5KsahcuTKGDRtW3NUoE4YNG4bKlSsXdzWITAqDHyrzevXqBRsbG8THx+stM2jQICiVSjx58qQIa0ZZfvjhhzIbSBKR8TH4oTJv0KBBSE5OxoYNG3TmJyUlYdOmTejSpQvKlStXxLUjgMFPbn7++WdcvXq1uKtBZFIY/FCZ16tXL9jb22PNmjU68zdt2oTExEQMGjSoiGtGBZGYmFjcVShSlpaWUKlUxV0NIpPC4IfKPGtra/Tt2xd79+5FVFSUVv6aNWtgb2+PXr16AQBu3ryJV199FS4uLrCxsUHLli2xdevWPM/ToUMHdOjQQSs9Z5+NrP5C8+bNw5IlS1ClShXY2NggMDAQd+/ehRACX375JSpUqABra2v07t0b0dHRWsfdvn072rZtC1tbW9jb26N79+4IDQ3VOrednR3u37+PPn36wM7ODm5ubvj444+hVqvzvCYhBL766itUqFABNjY26Nixo9Y5ssTExGDcuHHw8fGBSqVCtWrVMHv2bGg0mlzPUblyZYSGhuLgwYNQKBRQKBTSfVyxYgUUCgUOHjyId999F+7u7qhQoQIA4Pbt23j33XdRs2ZNWFtbo1y5cnj11VcRHh4uO37WMY4cOYLx48fDzc0Ntra2ePnll/Ho0SNZ2VOnTiEoKAiurq6wtraGr68vRowYISszb948tGrVCuXKlYO1tTWaNm2Kv//+W+e1/f7772jRogVsbGzg7OyMdu3aYdeuXbIy27dvR/v27WFvbw8HBwc0b95cFqjr6vOTmJiIjz76SLrXNWvWxLx58yCEkJVTKBQYO3YsNm7ciHr16kGlUqFu3brYsWOHVl3v37+PESNGwMPDQyr366+/apVbvHgx6tatK11Ts2bN9P7Hgqi4WBR3BYhKgkGDBmHlypX4888/MXbsWCk9OjoaO3fuxMCBA2FtbY3IyEi0atUKSUlJeP/991GuXDmsXLkSvXr1wt9//42XX37ZaHVavXo10tLS8N577yE6Ohpz5sxB//790alTJxw4cAATJkzA9evXsXjxYnz88ceyL6LffvsNQ4cORVBQEGbPno2kpCT8+OOPaNOmDUJCQmRflmq1GkFBQfDz88O8efOwZ88efPvtt6hatSreeeedXOs4depUfPXVV+jWrRu6deuGM2fOIDAwEGlpabJySUlJaN++Pe7fv4+33noLFStWxNGjRzFp0iQ8fPgQCxcu1HuOhQsX4r333oOdnR0+//xzAICHh4eszLvvvgs3NzdMnTpVavk5efIkjh49igEDBqBChQoIDw/Hjz/+iA4dOuDSpUuwsbGRHeO9996Ds7Mzpk2bhvDwcCxcuBBjx47FunXrAABRUVEIDAyEm5sbJk6cCCcnJ4SHh2P9+vWy43z33Xfo1asXBg0ahLS0NKxduxavvvoqtmzZgu7du0vlpk+fji+++AKtWrXCjBkzoFQqcfz4cezbtw+BgYEAMgOzESNGoG7dupg0aRKcnJwQEhKCHTt24PXXX9d5v4QQ6NWrF/bv34+RI0eiUaNG2LlzJz755BPcv38fCxYskJX/77//sH79erz77ruwt7fHokWL0K9fP9y5c0d6zBsZGYmWLVtKwZKbmxu2b9+OkSNHIi4uDuPGjQOQ+Qju/fffxyuvvIIPPvgAKSkpOH/+PI4fP663vkTFQhCRyMjIEF5eXsLf31+WvnTpUgFA7Ny5UwghxLhx4wQAcfjwYalMfHy88PX1FZUrVxZqtVoIIcStW7cEALF8+XKpXPv27UX79u21zj106FBRqVIlaTtrXzc3NxETEyOlT5o0SQAQDRs2FOnp6VL6wIEDhVKpFCkpKVJ9nJycxKhRo2TniYiIEI6OjrL0oUOHCgBixowZsrKNGzcWTZs2ze2WiaioKKFUKkX37t2FRqOR0j/77DMBQAwdOlRK+/LLL4Wtra24du2a7BgTJ04U5ubm4s6dO7meq27dujrv3fLlywUA0aZNG5GRkSHLS0pK0iofHBwsAIhVq1ZpHSMgIEB2HR9++KEwNzeXfgcbNmwQAMTJkydzrWvO86alpYl69eqJTp06SWlhYWHCzMxMvPzyy9J7JktWHWJiYoS9vb3w8/MTycnJOssIof3+2bhxowAgvvrqK9k+r7zyilAoFOL69etSGgChVCplaefOnRMAxOLFi6W0kSNHCi8vL/H48WPZMQcMGCAcHR2la+7du7eoW7eu/ptDVELwsRcRAHNzcwwYMADBwcGyxyJr1qyBh4cHOnfuDADYtm0bWrRogTZt2khl7OzsMHr0aISHh+PSpUtGq9Orr74KR0dHadvPzw8A8MYbb8DCwkKWnpaWhvv37wMAdu/ejZiYGAwcOBCPHz+WfszNzeHn54f9+/drnevtt9+Wbbdt2xY3b97MtX579uyRWqYUCoWUntUKkN1ff/2Ftm3bwtnZWVangIAAqNVqHDp0KO8bkotRo0bB3NxclmZtbS29Tk9Px5MnT1CtWjU4OTnhzJkzWscYPXq07Dratm0LtVqN27dvAwCcnJwAAFu2bEF6erreumQ/79OnTxEbG4u2bdvKzrlx40ZoNBpMnToVZmbyj+GsOuzevRvx8fGYOHEirKysdJbRZdu2bTA3N8f7778vS//oo48ghMD27dtl6QEBAahataq03aBBAzg4OEi/fyEE/vnnH/Ts2RNCCNnvLygoCLGxsdK1OTk54d69ezh58qTe+hGVBAx+iJ7J6tCc1T/h3r17OHz4MAYMGCB9sd6+fRs1a9bU2rd27dpSvrFUrFhRtp0VCPn4+OhMf/r0KQAgLCwMANCpUye4ubnJfnbt2qXVr8nKygpubm6yNGdnZ+l4+mRda/Xq1WXpbm5ucHZ2lqWFhYVhx44dWvUJCAgAAJ19rfLD19dXKy05ORlTp06V+r24urrCzc0NMTExiI2N1Sqf835nXUPWfWjfvj369euH6dOnw9XVFb1798by5cuRmpoq22/Lli1o2bIlrKys4OLiAjc3N/z444+yc964cQNmZmaoU6eO3mu6ceMGAKBevXoG3oVMt2/fhre3N+zt7WXp+t6jOa8bkP/+Hz16hJiYGCxbtkzr9zd8+HAAz39/EyZMgJ2dHVq0aIHq1atjzJgxOHLkSL7qT1QU2OeH6JmmTZuiVq1a+OOPP/DZZ5/hjz/+gBDCaKO8FAqFVodTAHo7FudsycgrPevYWR2If/vtN3h6emqVy95qlNvxjEmj0eCll17Cp59+qjO/Ro0aL3T87K0tWd577z0sX74c48aNg7+/PxwdHaFQKDBgwACdnazzuq8KhQJ///03jh07hn///Rc7d+7EiBEj8O233+LYsWOws7PD4cOH0atXL7Rr1w4//PADvLy8YGlpieXLl5fYTr+Gvp/eeOMNDB06VGfZBg0aAMgMsK5evYotW7Zgx44d+Oeff/DDDz9g6tSpmD59eiHUnqhgGPwQZTNo0CBMmTIF58+fx5o1a1C9enU0b95cyq9UqZLOOVWuXLki5evj7Oys81GSMVuLAEiPMNzd3aWWlcKQda1hYWGoUqWKlP7o0SOtVqOqVasiISGhwPXJ7TGPPn///TeGDh2Kb7/9VkpLSUlBTExMgeqQpWXLlmjZsiW+/vprrFmzBoMGDcLatWvx5ptv4p9//oGVlRV27twpG36+fPly2TGqVq0KjUaDS5cuoVGjRjrPk/V7vHjxIqpVq2Zw/SpVqoQ9e/YgPj5e1vpjyHtUFzc3N9jb20OtVhv0+7O1tcVrr72G1157DWlpaejbty++/vprTJo0SevxHVFx4WMvomyyWnmmTp2Ks2fParX6dOvWDSdOnEBwcLCUlpiYiGXLlqFy5cq5PsaoWrUqrly5Ihs+fe7cOaM/FggKCoKDgwO++eYbnX1Tcg7fLqiAgABYWlpi8eLFshYtXSO3+vfvj+DgYOzcuVMrLyYmBhkZGbmey9bWNt9Bi7m5uVZL2+LFiw0awq/L06dPtY6XFbhkPfoyNzeHQqGQnSM8PBwbN26U7denTx+YmZlhxowZWq1QWecIDAyEvb09Zs6ciZSUFJ1ldOnWrRvUajW+//57WfqCBQugUCjQtWvXvC82G3Nzc/Tr1w///PMPLl68qJWf/f2UcwZ0pVKJOnXqQAiRaz8poqLGlh+ibHx9fdGqVSts2rQJALSCn4kTJ+KPP/5A165d8f7778PFxQUrV67ErVu38M8//2h1Xs1uxIgRmD9/PoKCgjBy5EhERUVh6dKlqFu3LuLi4ox2DQ4ODvjxxx8xePBgNGnSBAMGDICbmxvu3LmDrVu3onXr1lpfjAWRNR/QzJkz0aNHD3Tr1g0hISHYvn07XF1dZWU/+eQTbN68GT169MCwYcPQtGlTJCYm4sKFC/j7778RHh6utU92TZs2xY8//oivvvoK1apVg7u7Ozp16pRr/Xr06IHffvsNjo6OqFOnDoKDg7Fnz54Cz9K9cuVK/PDDD3j55ZdRtWpVxMfH4+eff4aDgwO6desGAOjevTvmz5+PLl264PXXX0dUVBSWLFmCatWq4fz589KxqlWrhs8//xxffvkl2rZti759+0KlUuHkyZPw9vbGzJkz4eDggAULFuDNN99E8+bN8frrr8PZ2Rnnzp1DUlISVq5cqbOePXv2RMeOHfH5558jPDwcDRs2xK5du7Bp0yaMGzdO1rnZULNmzcL+/fvh5+eHUaNGoU6dOoiOjsaZM2ewZ88eaZ6pwMBAeHp6onXr1vDw8MDly5fx/fffo3v37lp9kIiKVXEMMSMqyZYsWSIAiBYtWujMv3HjhnjllVeEk5OTsLKyEi1atBBbtmyRldE11F0IIX7//XdRpUoVoVQqRaNGjcTOnTv1DnWfO3eubN/9+/cLAOKvv/6SpWcN1c45BHv//v0iKChIODo6CisrK1G1alUxbNgwcerUKanM0KFDha2trdY1Tps2TRjy8aBWq8X06dOFl5eXsLa2Fh06dBAXL14UlSpVkg11FyJzCP6kSZNEtWrVhFKpFK6urqJVq1Zi3rx5Ii0tLdfzREREiO7duwt7e3sBQBr2ru/ahRDi6dOnYvjw4cLV1VXY2dmJoKAgceXKFa265Xb/AIj9+/cLIYQ4c+aMGDhwoKhYsaJQqVTC3d1d9OjRQ3Y/hRDil19+EdWrVxcqlUrUqlVLLF++XO/9/PXXX0Xjxo2FSqUSzs7Oon379mL37t2yMps3bxatWrUS1tbWwsHBQbRo0UL88ccfUn7O90/Wvf7www+Ft7e3sLS0FNWrVxdz586VDZEXInOo+5gxY7Tqpev3FxkZKcaMGSN8fHyEpaWl8PT0FJ07dxbLli2Tyvz000+iXbt2oly5ckKlUomqVauKTz75RMTGxmqdg6g4KYTIpf2UiIiIqJRhnx8iIiIqUxj8EBERUZnC4IeIiIjKFAY/REREVKYw+CEiIqIyhcEPERERlSmldpJDjUaDBw8ewN7evkBT4xMREVHRE0IgPj4e3t7euU4c+yJKbfDz4MEDrdWviYiIyDTcvXsXFSpUKJRjl9rgJ2sq9bt378LBwaGYa0NERESGiIuLg4+PT6EuiVJqg5+sR10ODg4MfoiIiExMYXZZYYdnIiIiKlMY/BAREVGZwuCHiIiIypRS2+fHUGq1Gunp6cVdjVLD0tIS5ubmxV0NIiIivcps8COEQEREBGJiYoq7KqWOk5MTPD09Ob8SERGVSGU2+MkKfNzd3WFjY8MvaiMQQiApKQlRUVEAAC8vr2KuERERkbYyGfyo1Wop8ClXrlxxV6dUsba2BgBERUXB3d2dj8CIiKjEKZMdnrP6+NjY2BRzTUqnrPvKvlRERFQS5Tv4OXToEHr27Alvb28oFAps3LhRyktPT8eECRNQv3592NrawtvbG0OGDMGDBw9kx4iOjsagQYPg4OAAJycnjBw5EgkJCbIy58+fR9u2bWFlZQUfHx/MmTOnYFeYCz7qKhy8r0REVJLlO/hJTExEw4YNsWTJEq28pKQknDlzBlOmTMGZM2ewfv16XL16Fb169ZKVGzRoEEJDQ7F7925s2bIFhw4dwujRo6X8uLg4BAYGolKlSjh9+jTmzp2LL774AsuWLSvAJRIRERFlI14AALFhw4Zcy5w4cUIAELdv3xZCCHHp0iUBQJw8eVIqs337dqFQKMT9+/eFEEL88MMPwtnZWaSmpkplJkyYIGrWrGlw3WJjYwUAERsbq5WXnJwsLl26JJKTkw0+nikx5PdSmEr7/SUiosKT2/e3sRR6n5/Y2FgoFAo4OTkBAIKDg+Hk5IRmzZpJZQICAmBmZobjx49LZdq1awelUimVCQoKwtWrV/H06dPCrnKJFxERgffeew9VqlSBSqWCj48Pevbsib179xZ31YiIiEq8Qh3tlZKSggkTJmDgwIHS4qIRERFwd3eXV8LCAi4uLoiIiJDK+Pr6ysp4eHhIec7OzlrnSk1NRWpqqrQdFxdn1GspKcLDw9G6dWs4OTlh7ty5qF+/PtLT07Fz506MGTMGV65cKe4qEhFRKZSSrobS3AxmZqbfr7PQWn7S09PRv39/CCHw448/FtZpJDNnzoSjo6P04+PjU+jnLA7vvvsuFAoFTpw4gX79+qFGjRqoW7cuxo8fj2PHjunc58KFC+jUqROsra1Rrlw5jB49WtbB/MCBA2jRogVsbW3h5OSE1q1b4/bt21L+pk2b0KRJE1hZWaFKlSqYPn06MjIyCv1aiYioZIhLSYf/zL1445fjxV0VoyiUlp+swOf27dvYt2+f1OoDAJ6entIkeFkyMjIQHR0NT09PqUxkZKSsTNZ2VpmcJk2ahPHjx0vbcXFxBgdAQggkp6sNKmts1pbmBo+Oio6Oxo4dO/D111/D1tZWKz/r0WJ2iYmJCAoKgr+/P06ePImoqCi8+eabGDt2LFasWIGMjAz06dMHo0aNwh9//IG0tDScOHFCqtPhw4cxZMgQLFq0CG3btsWNGzekzunTpk0r+IUTEZHJCL0fh6dJ6Th64wn+PfcATxJSMay1b947llBGD36yAp+wsDDs379faxJBf39/xMTE4PTp02jatCkAYN++fdBoNPDz85PKfP7550hPT4elpSUAYPfu3ahZs6bOR14AoFKpoFKpClTn5HQ16kzdWaB9X9SlGUGwURr2a7h+/TqEEKhVq5bBx1+zZg1SUlKwatUqKWD6/vvv0bNnT8yePRuWlpaIjY1Fjx49ULVqVQBA7dq1pf2nT5+OiRMnYujQoQCAKlWq4Msvv8Snn37K4IeIqIywMH/+n/T3/ggBACgtzPG6X8XiqtILyfdjr4SEBJw9exZnz54FANy6dQtnz57FnTt3kJ6ejldeeQWnTp3C6tWroVarERERgYiICKSlpQHI/GLt0qULRo0ahRMnTuDIkSMYO3YsBgwYAG9vbwDA66+/DqVSiZEjRyI0NBTr1q3Dd999J2vZKYuEEPne5/Lly2jYsKGspah169bQaDS4evUqXFxcMGzYMAQFBaFnz5747rvv8PDhQ6nsuXPnMGPGDNjZ2Uk/o0aNwsOHD5GUlGSU6yIiopItQ639/fPZhgu4/SSxGGrz4vLd8nPq1Cl07NhR2s4KSIYOHYovvvgCmzdvBgA0atRItt/+/fvRoUMHAMDq1asxduxYdO7cGWZmZujXrx8WLVoklXV0dMSuXbswZswYNG3aFK6urpg6dapsLiBjsrY0x6UZQYVybEPObajq1atDoVAYvVPz8uXL8f7772PHjh1Yt24dJk+ejN27d6Nly5ZISEjA9OnT0bdvX639rKysjFoPIiIqmdLVGp3plx/Go1I57W4YJV2+g58OHTrk2gJhSOuEi4sL1qxZk2uZBg0a4PDhw/mtXoEoFAqDHz0VJxcXFwQFBWHJkiV4//33tfr9xMTEaPX7qV27NlasWIHExESp/JEjR2BmZoaaNWtK5Ro3bozGjRtj0qRJ8Pf3x5o1a9CyZUs0adIEV69eRbVq1Qr9+oiIqGRKy9Ad/DhYlfzvTl3K5NpepmzJkiVQq9Vo0aIF/vnnH4SFheHy5ctYtGgR/P39tcoPGjQIVlZWGDp0KC5evIj9+/fjvffew+DBg+Hh4YFbt25h0qRJCA4Oxu3bt7Fr1y6EhYVJ/X6mTp2KVatWYfr06QgNDcXly5exdu1aTJ48uagvnYiIiom+lp80PeklnWmGbGVYlSpVcObMGXz99df46KOP8PDhQ7i5uaFp06Y6pxSwsbHBzp078cEHH6B58+awsbFBv379MH/+fCn/ypUrWLlyJZ48eQIvLy+MGTMGb731FoDMySW3bNmCGTNmSB2ka9WqhTfffLNIr5uIiIqPviAnVU+LUEmnEAXpRWsC4uLi4OjoiNjYWNlQeyBz8sVbt27B19eX/VYKAe8vEVHp8uepu/j07/Na6YsGNkavht5GPVdu39/GwsdeRERElCtdj73KO1mjqpvpdXYG+NiLiIiI8pCzw3P7Gm5YOaJFMdXmxbHlh4iIiHKVM/j5JKimnpKmgcEPERER5Spn8ONsqyymmhhHmQ5+Smlf72LH+0pEVLqkZMjXv3S2sSymmhhHmQx+stYL4/IMhSPrvmbdZyIiMm0p6fKWn/ysTlASlckOz+bm5nBycpJWl7exsTF4ZXXSTwiBpKQkREVFwcnJCebmpv3HQUREmVLS5S0/pv6dWSaDHwDw9PQEACkAIuNxcnKS7i8REZm+k+HRxV0FoyqzwY9CoYCXlxfc3d2Rnp5e3NUpNSwtLdniQ0RUiuy7EolrkQnFXQ2jKrPBTxZzc3N+WRMREekxYsWp4q6C0ZXJDs9ERESUN41Ge/Tu+ndbFUNNjIvBDxEREemUmJYh236rfRU0qehcTLUxHgY/REREpFNcijz4ebNNlWKqiXGV+T4/REREpNvtx4kAACtLM1z5smsx18Z42PJDREREOiWkZrb81PZyKOaaGBeDHyIiItJpyYEbAEx/RuecGPwQERGRltQMNc7djQEAxCSVrvnwGPwQERGRlsTU50ta5FzewtQx+CEiIiItCdlGeiWlMfghIiKiUi4l43nAk9XxubRg8ENERERaRLbJnRn8EBERUakn8Dz6+W5Ao+KrSCFg8ENERERaslp+rCzN0LtR+eKtjJEx+CEiIiItWcGPvZVl8VakEDD4ISIiIi1Zj70UxVyPwsDgh4iIiLRktfyYKUpf+MPgh4iIiLRkBT+lMPZh8ENERETa+NiLiIiIypTnLT+lL/xh8ENERERaRN5FTBaDHyIiItIinjX9lMKGHwY/REREZY0QQgpu9JZ59i+DHyIiIjJpQggMWHYML/9wFBqN/gBI6vNTCrs8WxR3BYiIiKjoJKapcfxWNADg7tMkVCpnq6ckH3sRERFRKZCSrpZeJ6Wp9ZZ73vJT+jD4ISIiKkOSswU8yem5BD/P/uVQdyIiIjJpkXEp0mu1QX1+Sh8GP0RERGXI/Zhk6XW6WqO3nCjF0Q+DHyIiojIk+2OvXFt+nv1bCmMfBj9ERERlyc+Hb0qvM9QGPPZinx8iIiIyZTceJUqvM3Jt+eHCpkRERFTKZOTS5wdSy0/R1KUoMfghIiIqQyzNn0cz6Qb1+Sl90Q+DHyIiolIsKS1Deq3WCKRn6+ej1uQ22ivzX7b8ADh06BB69uwJb29vKBQKbNy4UZYvhMDUqVPh5eUFa2trBAQEICwsTFYmOjoagwYNgoODA5ycnDBy5EgkJCTIypw/fx5t27aFlZUVfHx8MGfOnPxfHRERURl2/OYT1Jm6E5UnboVGI2SzOwOQBULZZag1WHvyTlFUsVjkO/hJTExEw4YNsWTJEp35c+bMwaJFi7B06VIcP34ctra2CAoKQkrK80mVBg0ahNDQUOzevRtbtmzBoUOHMHr0aCk/Li4OgYGBqFSpEk6fPo25c+fiiy++wLJlywpwiURERGXTm6tOSa/vxyTj0sM4Wb6+oe5LD97AlvMPAZTO0V75Xti0a9eu6Nq1q848IQQWLlyIyZMno3fv3gCAVatWwcPDAxs3bsSAAQNw+fJl7NixAydPnkSzZs0AAIsXL0a3bt0wb948eHt7Y/Xq1UhLS8Ovv/4KpVKJunXr4uzZs5g/f74sSCIiIiL94lOeP/JqO2e/Vr6+Ds9rjj9v9Sl9oY+R+/zcunULERERCAgIkNIcHR3h5+eH4OBgAEBwcDCcnJykwAcAAgICYGZmhuPHj0tl2rVrB6VSKZUJCgrC1atX8fTpU53nTk1NRVxcnOyHiIioLKvt5ZBrfvbHXiuPhmP6v6EQQuBB7POnNaWw4ce4wU9ERAQAwMPDQ5bu4eEh5UVERMDd3V2Wb2FhARcXF1kZXcfIfo6cZs6cCUdHR+nHx8fnxS+IiIjIRGk0Apcf5t4QsPXCQ+n1tM2hWH4kHKdvyxsZGPyUYJMmTUJsbKz0c/fu3eKuEhERUbG59SQxzzKnbz+FWiNkfX+iE9NkZTjUPQ+enp4AgMjISFl6ZGSklOfp6YmoqChZfkZGBqKjo2VldB0j+zlyUqlUcHBwkP0QERGVVTFJaXkXArD25B0kZxsFFnzziSyfLT958PX1haenJ/bu3SulxcXF4fjx4/D39wcA+Pv7IyYmBqdPn5bK7Nu3DxqNBn5+flKZQ4cOIT09XSqze/du1KxZE87OzsasMhERUakUm5yedyEA1yLikZT6vGP08iPhsnyhfx5Ek5Xv4CchIQFnz57F2bNnAWR2cj579izu3LkDhUKBcePG4auvvsLmzZtx4cIFDBkyBN7e3ujTpw8AoHbt2ujSpQtGjRqFEydO4MiRIxg7diwGDBgAb29vAMDrr78OpVKJkSNHIjQ0FOvWrcN3332H8ePHG+3CiYiISrO45Ay9eYsHNpZerwy+jbN3Y6RtVzulrOyThFSj16245Xuo+6lTp9CxY0dpOysgGTp0KFasWIFPP/0UiYmJGD16NGJiYtCmTRvs2LEDVlZW0j6rV6/G2LFj0blzZ5iZmaFfv35YtGiRlO/o6Ihdu3ZhzJgxaNq0KVxdXTF16lQOcyciIjJQbi0/jSs6oU8jb2w8+wAAMPq3509jHifIH5c9STTs8ZkpUQhRGhu0Mh+3OTo6IjY2lv1/iIiozFm8Nwzf7r6mM+/k5wGY/m+oNJFhXsJndTdm1XJVFN/fpWa0FxERET0Xk0vLj5WlGdJzW9G9lGPwQ0REVApduBerN8/K0lzv0hZlAYMfIiKiUubi/VicCI/Wm29hptC7qGlOr/tVNFa1Sox8d3gmIiKiku3VpcG55isUCmRocn/s1bKKC1IzNBj/Ug1jVq1EYMsPERFRKZN90sIN77bCW+2raJXJyNHyUyfHOmCDW1bGhndbw9VOVTiVLEYMfoiIiEqxmp72mNS1Nqq42srSG1V0km3bW8kfBrnZl76gJwuDHyIiolIk5/w+NsrMoKZjrcxFxbMmMfygc3WYZVu6Iufor+aVS++KCuzzQ0REVIr0WHxYZ/rHgTVRqZwNOj0LgmyUFrg0owtqTdkBALIO0K52KihK46JezzD4ISIiKiWEELgbnawzz1ppjiH+lWVpVpbm0msH6+chgdK89AY+AB97ERERlRo5h693r++V5z4z+9ZHHS8HTO9VT0qztCjd4QFbfoiIiEqJnP12vn+9sZ6Szw1sUREDW8jn8mlQwcmY1SpxSndoR0REVIbkDH7y229n3eiW8K9SDuMCqhuzWiUOW36IiIhKieyPvT7onP8Axq9KOfwxupwxq1QiseWHiIiolMje8vNhKZyZ2VgY/BAREZUSWcGPjdI8j5JlG4MfIiKiUiI+JQMAYKdir5bcMPghIiIqJbJmd3a0tizmmpRsDH6IiIhKCQY/hmG7GBERkYm7eD8WX2wOhbeTNQAGP3lh8ENERGTi+v5wFGlqDXD7KQDA3cGqmGtUsvGxFxERkYlLyzG5YSMfx2KqiWlg8ENERFTK2Kn42Cs3DH6IiIhKmVpe9sVdhRKNwQ8REVEpU9XNrrirUKIx+CEiIjJxLrZK6XUFZ+tirIlpYPBDRERk4hJSM6TXao3IpSQBDH6IiIhMWrpag7SM56O9hvhXLr7KmAjO80NERGTCErO1+qwZ5Qc/33LFWBvTwOCHiIjIhD1NylzSQmVhhlZVXYu5NqaBj72IiIhMWPiTRACAr6ttMdfEdDD4ISIiMmGp6Zn9fWyU5sVcE9PB4IeIiMiEZS1tobJg8GMoBj9EREQmLGukl9KCX+mGYodnIiIiE/Prf7dQ3tka/lXL4eO/zgFg8JMfDH6IiIhMSPjjRMzYckkrXcXgx2C8U0RERCbkaVKaznR7K7ZnGIrBDxERUTGJS0lHhlqTd8FsktLUOtOT9aSTNoaJRERExeBxQiqafbUHAHDzm24wM1MYtN+DmGSd6b6uXMndUGz5ISIiKgYnb0VLr2dsuYSo+JRcy5+9G4PKE7fik7/PS2kda7pJr9/tWNX4lSyl2PJDRERUDJYfDZderzgajjUn7uDaV131lu+z5Ihse06/Bujf3AcPYpJhb2UBS3O2ZxiKwQ8REVExOJGt5QeAbGV2Q7g5qAAA3k7WRqtTWcEwkYiIqBhYW2rPyJySbnin5bpeDsasTpnC4IeIiKiEiEtJ15kuhNBKs+PQ9gJj8ENERFTEhBBI1tHKE5ecobN8Srr2IzFdLUdkGAY/RERERSxVT/8efS0/16MStNIUCsOGxpM2Bj9ERERFLFVHSw4AJKbqbvnp+f1/sm0LA+cEIt2MHvyo1WpMmTIFvr6+sLa2RtWqVfHll1/KnlcKITB16lR4eXnB2toaAQEBCAsLkx0nOjoagwYNgoODA5ycnDBy5EgkJGhHvkRERKYmJUN3x+YMjXbfHl2doF3tVEavU1li9OBn9uzZ+PHHH/H999/j8uXLmD17NubMmYPFixdLZebMmYNFixZh6dKlOH78OGxtbREUFISUlOcTPA0aNAihoaHYvXs3tmzZgkOHDmH06NHGri4REVGRywpobJXyfjsaHcGPruUsHK0tC6diZYTRg5+jR4+id+/e6N69OypXroxXXnkFgYGBOHHiBIDMVp+FCxdi8uTJ6N27Nxo0aIBVq1bhwYMH2LhxIwDg8uXL2LFjB/73v//Bz88Pbdq0weLFi7F27Vo8ePDA2FUmIiIqUllz/CSmqbHvo/ZSutrAlp9ejbwLr3JlgNGDn1atWmHv3r24du0aAODcuXP477//0LVr5qyVt27dQkREBAICAqR9HB0d4efnh+DgYABAcHAwnJyc0KxZM6lMQEAAzMzMcPz4cWNXmYiIqEhN+Of5EhVV3OzQrJIzAECjY0h79uBnz/j2+PbVhhjZxrfwK1mKGX2SgIkTJyIuLg61atWCubk51Go1vv76awwaNAgAEBERAQDw8PCQ7efh4SHlRUREwN3dXV5RCwu4uLhIZXJKTU1FamqqtB0XF2e0ayIiIjImczMFNOrngU7Woqa6Fnh/FJ/53aZQANXc7VDNnQuYviijt/z8+eefWL16NdasWYMzZ85g5cqVmDdvHlauXGnsU8nMnDkTjo6O0o+Pj0+hno+IiKig+jauAOD5qC3zZ8PW1TpafhbtyxwQpCOLCsjowc8nn3yCiRMnYsCAAahfvz4GDx6MDz/8EDNnzgQAeHp6AgAiIyNl+0VGRkp5np6eiIqKkuVnZGQgOjpaKpPTpEmTEBsbK/3cvXvX2JdGRET0wh7EJCPtWRPPR4E1AQBJzx5tPY5P1SqfNcFh88rORVTD0s/owU9SUhLMzOSHNTc3h0aT+cvz9fWFp6cn9u7dK+XHxcXh+PHj8Pf3BwD4+/sjJiYGp0+flsrs27cPGo0Gfn5+Os+rUqng4OAg+yEiIipJToZHo9WsfdgQch8AYP9siYpzd2MAADO2XMLRG4+RnG2El7NN5siuvk0qFG1lSzGj9/np2bMnvv76a1SsWBF169ZFSEgI5s+fjxEjRgDInJFy3Lhx+Oqrr1C9enX4+vpiypQp8Pb2Rp8+fQAAtWvXRpcuXTBq1CgsXboU6enpGDt2LAYMGABvb/ZwJyIi07T62G3ZtoOOIeuv/3wc5WyVOD3lJQDPZ4NWmnNeYmMxevCzePFiTJkyBe+++y6ioqLg7e2Nt956C1OnTpXKfPrpp0hMTMTo0aMRExODNm3aYMeOHbCyspLKrF69GmPHjkXnzp1hZmaGfv36YdGiRcauLhERUZGp7Gor27bXszjpk8Q0xCSlwclGibSs4MeCwY+xGD34sbe3x8KFC7Fw4UK9ZRQKBWbMmIEZM2boLePi4oI1a9YYu3pERETFxlYp/9p1ymWywpA7MehQ003qH8Tgx3iMHvwQERGR3O0nifjv+mPEJssXLi1nq3+ZiuErTqKCszXuPU0GwMdexsTgh4iIqBAlp6nRfu4BnXk+LtYAgPn9G2L8n+e08rMCH4AtP8bEO0lERFRIUjPUqD11h958xbP5fdztrfSWycLgx3h4J4mIiArJ3ejkvAsBUFnm/XXMx17GwztJRERUSNJ1rVehQ5OKeU9gyJYf4+GdJCIiKgTxKelISM3Qm794YGPptfmzZS5yw+DHeNjhmYiIyMjCIuPR5bvDcLVTauWtGeWHppWcobIwz9cxy9lqH4sKhmEkERGRkS07dBNqjUBk3PO1uq582QXhs7qjVVVXnYFP3ybltdJGtPaVXjvZMPgxFgY/RERERmarkj9Y6VDTDVaWubf0tK/hppX2StMKKGerxMAWPkatX1nHx15ERERGZquSBzoJKfr7/mTR1e+ngos1TnweYFCfIDIcW36IiIiM7HpUgmw7OjEtz33sVNrtEdaW5gx8CgFbfoiIiIxsZ2ikbDu3UV9ZvJ2spdf+VcqheWVnWHJun0LB4IeIiKiQzX6lQZ5lVNmGsn/Zpx6qudsVZpXKNAY/RERELyhdrUH3RYdxLTIBBz/pgPJO1rgfk4yfhzSDXxUXOFjpX709S/ZWHs7mXLgY/BAREb2gQ9ce4VpkZj+frt8dlmZ2ruVpb1DgA8gnMTQ3Zz+fwsTgh4iI6AWtOX5Hep2UppZeV3C21lVcJ/bvKToMfoiIiAooNjkdY1afwX/XH+vMz1q13RAW2UZ1cYBX4WLwQ0REVEA/HLiuN/DJL1uVBV5tWgEpGRp4OlgZ5ZikG4MfIiKiAnoQk2LU4819taFRj0e68QEjERFRAemamDCLlyNbb0oqBj9EREQF5GwjH8lV1c1Wem2Wj/4+VLQY/BARERVQcrpatv3HqJbSazN+w5ZY/NUQEREVUEq6Rrbtnq2jsjlbfkosBj9ERFTmJaep0X3RYXyxOTRf+6XkaPnJjo+9Si4GP0REVObtvxqF0AdxWHE0PF/7JWeb0PDk5wGyPDd7lTGqRoWAwQ8REZV52RcVzR7Q5CUxLXO19nmvNpSCnf8NaYbmlZ0xx4DFTKl4cJ4fIiIq88yyTamclJYBa6V5nvscDnuEw2GZExxaWz4vH1DHAwF1PIxfSTIatvwQEVGZdOzmE9SYvB0zt11Gara+OzlHcOkzatUp6bW1kl+npoQtP0REVCYNWHYMAPDToZuy9Nw6MWdnYWYGIHO0l5Vl3i1FVHIwVCUiojLnrd9O6c3LOXxdn+z9hKwZ/JgUBj9ERFSmCCGwMzRSb75aIww6jo3qecBjSB8hKjkY/BARUZmSps69ZSfDwOCnoouN9NrKgsGPKWHwQ0REZUpKWu7Bj0YYFvzYKp93m2XLj2lh8ENERGXKsVtPcs039LGXebbh8Zbm/Do1JfxtERFRmfLWb6dzzTc0+HHKtqK7o7VlLiWppGHwQ0REZUrb6q655hsa/GR5v1M1WSsQlXwMfoiIqEzxyLbyui6GBj8Z6sxyKg5zNzkMfoiIqEzJaxJDQ4Mf9bOO0RZs9TE5DH6IiKhMSc0wzlB3zbNyfORlehj8EBFRmZK95WeujpXXNUIgOU0tBTe6ZKg1SHq2+ruZgsGPqeHaXkREVKakPlu+4odBTdCtvhequtsh5E4MDlyNwuGwx7j5KAHvrj6DllVcsHa0v85jtJ69D5FxqQDY8mOKGPwQEVGZkpSeAQCwssx8+NGkojOaVHTG44RUHA57jHm7rgEAjt2M1rl/aoZaCnwABj+miI+9iIiozEjNUOPi/TgA2o+r3O1VBh0jMVXeYZrBj+lh8ENERGXGnktR0uucq7dbGDhLc3xKumzbnH1+TA6DHyIiKjPisgUuHWu5yfKU5oYFMY/iU2XbZmz5MTkMfoiIqMyIS84Mfvo2Lg9VjpXYLcwM+0p8kpgm2+ayXqaHvzIiIiozYp8FP442BV+LKz4lQ7adrs7fchhU/Aol+Ll//z7eeOMNlCtXDtbW1qhfvz5OnTol5QshMHXqVHh5ecHa2hoBAQEICwuTHSM6OhqDBg2Cg4MDnJycMHLkSCQkJBRGdYmIqIx4mvQs+NGxEGmaOvfJD7Pk7POTkCMYopLP6MHP06dP0bp1a1haWmL79u24dOkSvv32Wzg7O0tl5syZg0WLFmHp0qU4fvw4bG1tERQUhJSUFKnMoEGDEBoait27d2PLli04dOgQRo8ebezqEhFRGRL+OBEAUMHZRisvw+DgRx7sJKYy+DE1Rp/nZ/bs2fDx8cHy5culNF9fX+m1EAILFy7E5MmT0bt3bwDAqlWr4OHhgY0bN2LAgAG4fPkyduzYgZMnT6JZs2YAgMWLF6Nbt26YN28evL29jV1tIiIqA5LSMgMVZx2PvbrV98KUTaF5HmPpwRuy7YQ0Bj+mxugtP5s3b0azZs3w6quvwt3dHY0bN8bPP/8s5d+6dQsREREICAiQ0hwdHeHn54fg4GAAQHBwMJycnKTABwACAgJgZmaG48eP6zxvamoq4uLiZD9ERETZpT3rn2Opo5dyOTsV6pd3zHX/8X+elZa1yFLTw954FaQiYfTg5+bNm/jxxx9RvXp17Ny5E++88w7ef/99rFy5EgAQEREBAPDw8JDt5+HhIeVFRETA3d1dlm9hYQEXFxepTE4zZ86Eo6Oj9OPj42PsSyMiIhOX/uzRlq7gBwBUFrl/La4/c196/X7n6viyTz30blTeeBWkImH0x14ajQbNmjXDN998AwBo3LgxLl68iKVLl2Lo0KHGPp1k0qRJGD9+vLQdFxfHAIiIiGSygh+lhe65eU7dfirb1miENI+PEPJRXQG13dGggpPxK0mFzugtP15eXqhTp44srXbt2rhz5w4AwNPTEwAQGRkpKxMZGSnleXp6IioqSpafkZGB6OhoqUxOKpUKDg4Osh8iIqLs0jNyb/nJSZMt4ElOlz/u0tVpmkyD0YOf1q1b4+rVq7K0a9euoVKlSgAyOz97enpi7969Un5cXByOHz8Of//M1XP9/f0RExOD06dPS2X27dsHjUYDPz8/Y1eZiIjKiNz6/OiSoXke/OQc0u5iqzRexahIGf2x14cffohWrVrhm2++Qf/+/XHixAksW7YMy5YtAwAoFAqMGzcOX331FapXrw5fX19MmTIF3t7e6NOnD4DMlqIuXbpg1KhRWLp0KdLT0zF27FgMGDCAI72IiKjA8urzk1NqhgYaIXD/aTKuRMRL6W+3r1oo9aOiYfTgp3nz5tiwYQMmTZqEGTNmwNfXFwsXLsSgQYOkMp9++ikSExMxevRoxMTEoE2bNtixYwesrKykMqtXr8bYsWPRuXNnmJmZoV+/fli0aJGxq0tERGWI1OfHwOAnOU2ND9afx4Grj2TpE7vWMnrdqOgoRM4eXKVEXFwcHB0dERsby/4/REQEjUagymfbAADBkzrBy9Faq8z83dewaO/zFQf2fdQenb49qFUufFb3wqtoGVcU399c24uIiMqEJfuvS6/1PfY6eE3ewpOzkzMAvNaMI4lNHYMfIiIqE77dfU16rS/4qelhJ9vO0LFoqZUlvzpNHX+DRERU5ujr8/N5tzro2+T5pIXpOtb7srcq+IrwVDIw+CEiojLH0lz3JIeONpaY378RajxrAYqMS9Uuo2NFeDItDH6IiKjMschjtFfWY7Exa85o5TlYG32gNBUxBj9EREQ55DYPkKFzBFHJxd8gERGVanEp6dBkm6m5b+O8FyLNbR4gZxvO7Gzq2HZHRESl1saQ+xi37iza13CT0t5sWyXP/SxzLHzaqmo51PJ0QGRcCtpWdzV6PaloMfghIqJSa9y6swDk8/doDJjbN+ejrc+61Ua98o5GrRsVHz72IiKiMqWWp32eZXIGP0oLfl2WJvxtEhFRqbD04A1UnrgVH/91Dlci4vSWy2ukFwDEJafL9zHTPTSeTBODHyIiKhVmbb8CAPj79D10WXgYD2OTC3ys47eiZdsc4VW68LdJREQm77+wx1ppR68/0Up7p0PVAh3fWmleoP2oZGLwQ0REJm/uzitaaVM2XdRK++ilGgYdL6C2h2zbTsXxQaUJgx8iIjJ51dy1OzEnpWmvyG5Ifx8ACKjtLttWscNzqcLfJhERmbzyztZGPV7OPj4KBTs8lyYMfoiIyORlzeAcVNfDoKHsebHItvCpITNCk2lh8ENERCZP/WziQm8na9Tw0B385KfxJvvyFnZW7O9T2jD4ISIik5c1a7O5QqF3WHp+Hlxl7xtky87OpQ6DHyIiMnlZj73MzRR6Z2M2y0fTj2W2x14c6VX6MPghIiKTp9Zk/mtmptA7Mis/j72ytx7Z87FXqcPgh4iITF72x176Wn7yM2Ire/Bjq2TwU9rwN0pERCZP/eyxl5mZAuZCd5DjkI8WnOyjvdjhufThb5SIiExeVsuPmULesfn71xtDaW6Gr7ddxsLXGhl8vOyjvezZ56fU4W+UiIhMmhACq4/fAQAkpGTAMttjr4DaHrCyNEdgXc98HTN7yw9He5U+7PNDREQmLSIuRXp95IZ8MdOCrsZubfl8IVM+9ip9GPwQEZFJi4pLlV4rADx7AgYgc+h7QbjYKqXXlmb8qixt+BslIiKTFp+SIb2e80oDoxzTTmWBl+p4oGUVF1Qw8rphVPzYlkdERCYtMS0z+GlS0Qn1yjvi3/MPXviYCoUCPw9p9sLHoZKJLT9ERGTSkp4FP1LHZJFLYSIw+CEiIhMX+azPj8ois5MyYx/KC4MfIiIyabO2XwEA7LkcCQBISVcXZ3XIBDD4ISKiUqV9DTcAQHkndlQm3djhmYiISoXXmvkAADrVcsefb/mjhoddMdeISiq2/BARkUmr5WkPAOjewAtA5kitFr4ucLJR5rYblWEMfoiIyKQl5hztRZQHvlOIiKhEu/QgDneiE9Glnpcsff/VKGw9/xCP4jNHe9kx+CED8Z1CREQlWrdFhwEAf73tj+aVXaT04ctPysrZqsxBZAg+9iIiIpNwKvyp9Do1Q3s4O1t+yFB8pxARkUm4GhEHjUZgyqaLWH38jla+jZJfaWQYvlOIiMgkbDz7ABvP6l+3S2nBhxlkGL5TiIiIqExh8ENERCZvdLsqxV0FMiF87EVERCarTTVX/DayBRQKRXFXhUwIgx8iIjIp9lYWsDTPfHDxbf+GDHwo3xj8EBFRiaayMENqhgYAMKdfA3Rr4MVh7fRCCr3Pz6xZs6BQKDBu3DgpLSUlBWPGjEG5cuVgZ2eHfv36ITIyUrbfnTt30L17d9jY2MDd3R2ffPIJMjIyCru6RERUwmiEAAAc/rQj+jf3YeBDL6xQg5+TJ0/ip59+QoMGDWTpH374If7991/89ddfOHjwIB48eIC+fftK+Wq1Gt27d0daWhqOHj2KlStXYsWKFZg6dWphVpeIqFQSQmBVcDjO3o0p7qoUiCYz9uFQdjKaQnsnJSQkYNCgQfj555/h7OwspcfGxuKXX37B/Pnz0alTJzRt2hTLly/H0aNHcezYMQDArl27cOnSJfz+++9o1KgRunbtii+//BJLlixBWlpaYVWZiKhUWX/mHlrP2offj93G1E2h6LPkCO49TSruauWb+ln0Y8a+PWQkhRb8jBkzBt27d0dAQIAs/fTp00hPT5el16pVCxUrVkRwcDAAIDg4GPXr14eHh4dUJigoCHFxcQgNDS2sKhMRlRop6WqM//Mc7sckY8qm55+bbWbvL8Za5Z949sgLAMwY+5CRFMqD07Vr1+LMmTM4efKkVl5ERASUSiWcnJxk6R4eHoiIiJDKZA98svKz8nRJTU1FamqqtB0XF/cil0BEZNIexqYUdxWMIqvVB2DLDxmP0YOfu3fv4oMPPsDu3bthZWVl7MPrNXPmTEyfPr3IzkdEVBKlZqgxe/tV3IlOLO6qGEW22AdmbPohIzH6Y6/Tp08jKioKTZo0gYWFBSwsLHDw4EEsWrQIFhYW8PDwQFpaGmJiYmT7RUZGwtPTEwDg6empNforazurTE6TJk1CbGys9HP37l1jXxoRUYm3/sx9/HrkFvZcjiruqhSIEEL2qOvW4+dBHGMfMhajBz+dO3fGhQsXcPbsWemnWbNmGDRokPTa0tISe/fulfa5evUq7ty5A39/fwCAv78/Lly4gKio53+8u3fvhoODA+rUqaPzvCqVCg4ODrIfIqKyJiwyobirUGChD2LhO2kbRqx43mVi3Lqz0muVhXkx1IpKI6M/9rK3t0e9evVkaba2tihXrpyUPnLkSIwfPx4uLi5wcHDAe++9B39/f7Rs2RIAEBgYiDp16mDw4MGYM2cOIiIiMHnyZIwZMwYqlcrYVSYiKjU02VpNAODVphXw9cv1UWPy9mKqkWH2Xo7EyJWnAAD7rz6CWiNw9m4MLj983n+TQ93JWIrlnbRgwQL06NED/fr1Q7t27eDp6Yn169dL+ebm5tiyZQvMzc3h7++PN954A0OGDMGMGTOKo7pERCYjMVU+Gexb7atAaWGGha810iorhMCeS5GISSreKUQSUzOkwCfLrtAI/LD/urStYuBDRlQk02QeOHBAtm1lZYUlS5ZgyZIlevepVKkStm3bVsg1IyIqXSLino/y6lzLHb6udgCAttVdpXSNRsDMTIEFu69h0b7r6FLXE0sHNy3yumbJ3rqT5Z3VZ2Tb5WyVRVUdKgM4RzgRUSkS8WyI++8j/dAmW8BjYf685SRDIxAWEYdF+zJbVnaE6p5CpKi8sjQ4zzL+VV3zLENkKAY/RESlxPl7MQiLyuzw7Oko7x9pkW2oVIZGg+mbLxVp3fQROfoo6fJ2+6p4p0PVIqgNlRV8iEpEVApExaeg349HpW1PR2tZvoV59uBH4ER4tLTtbGNZ+BXUIzFNLb3+bkAjrXyVhRkmdq0FR+viqyOVPmz5ISIycZUnbtVKy7nyuaXZ8//rbjr7QJYXm5wOtUbA3MCJdMIi4+HjYgMryxcfer738vM53Xo19MbjhDR8uSWzVaqhjxPWvOn3wucgyonBDxFRGZB9duQpGy/K8jQCiElKQzm7vKcSWXfyDib8cwHlnaxxZGKnF65X9nmJFAoFRrSujC71POHtaAUFl7OgQsLHXkREpcxfb/vne5/IuNQ8y6SkqzHhnwsAgPsxyfk+hy5ZQdkbLSsCyAyAyjtZM/ChQsXgh4iolKniamtQua/6PJ+QdsGea3mW31kIo8KSns1LZKvkgwgqOgx+iIhMnNJc/lHuZGPYnDjlnZ93ik5IycilZKbUDI3evKS0vPfXJePZyqWW5vw6oqLDdxsRkYlL18iDEkM7LrvZqdC9gRcAoLqHXZ7l03IEP1mLkI7/8yzqTduJw2GPDKzxc+pnwQ9XbKeixOCHiMiEaTQC2afKqeBsrbesU7Yh7Y7Wlqjj5YAa7vYAgFXBt6UJEvVJSVfLttUageVHwrH+zH1oBLDm+J1811/9rPLm7ONDRYgPWYmITFjWYyMgcwmLL3rV1Vs2ZMpLACDrTOxg/fxr4M9Td+HlaIWgep5wsJLPqyOEwNKDN7XOPWPL88kSr0bG6z33TwdvYNelSKwc0UI2DF/zrP586kVFicEPEZEJy8j2yGvZ4GawVuqfe0fXCCo3++fD2+fvzuz0vDM0Ev8b2gwAsO9KJEasOKW1HwAE33gi267mpvvRWURsCmZuvwIA+OvUXQxv7Svl8bEXFQfG2kREJuz07afSa0P7+mTXrZ6XVtqebBMP6gt8AGD4ipOy7V2XIvHTwRta5Q5de94XKGcd+diLigODHyIiEzb4lxPSa0vz/AcQZmYK9GrorTMvNUOtMz03M7dfwd3oJGlbrRH49J/z0nbOWaGfP/Zi8ENFh8EPEVEpYeyJAWOT0g0qt2d8e9l22zn7ERWf2Xn66I3HsrxtFx7KtrP6LJmx5YeKEIMfIiITdDI8Gh3nHZC2m1R0KvCxNDlWVvdwyOwHlJSWd8uPmUL3pIotvt4L4HmfnixejlY6z21RgFYrooJi8ENEZGIexibj1aXBuPU4UUob2qpygY+XI/ZB2+puAIDEZxMXOtlY4qOXamDOKw2wakQLWVlnGyXMzBQInqS9ztejeO0lM/49J2/5UbPlh4oBgx8iohJKCIHrUQlarSf+M/dplVVZFHyF9dHtqsi21ZrMyQvHrgkBANhbWeC9ztXRv5kP2tVww7BsgVbW5IhejtYIn9VddpzmX+/BvitRsrSE1AwkpGbgQUwyhBDSiDH2+aGixKHuREQlkBACn2+8iDXH72CofyVM710v1/Iqi4L/X7ahj5Nse0PIfdTwsJdalu5GyxcxzT6RYs68kCkvofGXu6XtVcG3AQCeDlaIiMvsB1Rv2k4AwFD/Soh7tqwGR3tRUWLLDxFRCdRq1j5pxuSVzwIIQLsPTZbs8/UUxJx+DWTbs3dc0Vs2+8SKPw1uKstzttW9rpiPi/bM09mvyyqX+YmIjI3BDxFRCaPWCDzMsdTEsZuZj4f0LUBa19vhhc7Zv7kPvnm5vs68lxuXl22/VMcDQGZH53rlHQ06fl59khJTC7YwKlFBMPghIiph4pK1h5ivftYK9NnGC1p5Nkpzowxz19XtplMtd3zZR/7IraqbHQ5/2hFb3m+j8zhzXmmglebpYIWvX9b/6K5TLff8VZboBTD4ISIqYWJ0BD//nnuAR/Gp2Hr+oVZeVx2zNBdEvI5WpU+71JStxZXFx8UGNkrd3UZfbVoBNT3sZWkVnG2kFqOcBresBA8HK515RIWBwQ8RUQkTk5Qmvc4+smrR3jDpdQVnaywf3hxBdT0wqVsto5y3o47Wl8rltOfwyYtCoYB/1XKyNHd7lc4gCsh9JXqiwsDgh4iohDkVnrleVyMfJ3zRqy48n7WK/HYss4OwuZkCf4xqiY413fHT4GZwtXuxzs5ZqrnbyTowj3+phtZyFIZ6lPB8jp/gSZ1gZqaAjdICk7vXxuTutWVl1TknGiIqZAx+iIiMLCo+BRlqTd4F9bj4IBbA834wb7WXz8PzVrsq8HGxKXgFc9HS93mLzYtMnJiW8fz6vRyft+y82bYK3mxbBX++5S+l+RagdYnoRXCeHyIiI7p4PxY9Fv+HdjXctGZDzo1aI7DtwkNcvB+LzeceAMhsiQGAmp7y/jN6RrsbhaONJWb1rQ8zhQKO1pYFPs6HATVw/l4MPuhcQ2d+s0rOqO3lgHvRSQiq61ng8xAVBIMfIiIjWn0889HUoWuP8rXfmuO3MWVTqCytfY3MZSayt8YABVttPT8GtKj4wseo4+2A458F6M03M1Ng27PRYsZekJUoL3zsRURkRDmXaXickIpWM/ei9pQdeBCTORuyEAJ7L0di96VIqdzak3dl+9X0sIftsw7CZmYK3PymmzRR4Icv6W5NMTUKhYKBDxULtvwQERnJqfBo/H7sjrQdm5SOb7ZdxoNnExaOWnUK8/s3QtDCQ1KZK192QUq6Wmthz9pe8kddZmYKHP5Ue/FQIso/hRCls5t9XFwcHB0dERsbCweHF5v5lIgoL2kZGtSYvD3PcmYKw/rsLH2jKbrUY18YKnuK4vubLT9EREaw93Jk3oWQd+Dj4aDCK00r6J0QkIheHIMfIiI9rkfFI2D+IQzyqwi/KuXwUm0PWOtYgHPhnmtYuCdMxxHyb/f49nCwKvgoKyLKG4MfIiIdbj9JRMD8zL45q4/fkdbWCp/VXVYuJV0tC3yqudvhelRCgc7534SODHyIigBHexER6ZAV7OQmOU2NKRsvytLaVnfFRzlGY73WzCfX40ztUQeHP+2ICs6FM3EhEcmx5YeISAd961AJIaTh2XWm7UDOISO1PO3xWvOK6NO4PHaGRuCNlpVgZWmOdaeeD2VvW90Vh8MeS9uDWlaEyqJgy0gQUf6x5YeISpw9lyJxKjy62M6flqHB/N3XdOb9/qxFSAihFfgAgLdT5lw8Pi42eLNtFWltrJ3j2mFYq8o4/llnrZmfGfgQFS0GP0RUIgghoNEIPIxNxpurTuGVpcEvtD7Wi8g+ZD2orgeaVnKWtqdsvIgMtQY3HiXq3NfNXvciozU97fFFr7rwcLCCQqHAW+0y1+t6p0NVI9aciAzB4IeISoRhy0+i07cHEPFsQkAA2HL+YZHXY9PZ+7LtWX0b4J93WsnSouJTsePi87odndgJbau7oq63A6q62Rl0nkndauPctEBM6FLrxStNRPnCPj9EVOyeJqbh4LO1sIJvPpHSlx26iT6NyxdJHY7eeIzZO67i3N0YKe3wpx3hbKsEAPz5lj/6/xQMAGg1ax+sLDP/7xhYxwPeTtb4baSfrD+QIV5k4VAiKjgGP0RU7GKT06XX/5y+J72+9DDOKMePT0lHaoYGrna6H0kBwLi1ZxEVnyptB9T2gI/L89FXLXxdZOVT0jMfyfVrWkFK4zpVRKaBj72IqNglpz9fpVxfX5oXMfDnY2j21R6tTtQZag1WBYfj9O1oWeADAJ8E1TTo2BWcrY1WTyIqGgx+iKjYJaWp9ea96PKDqRlqXLyf2YL0ytJgHLn+fIj5p/+cx9RNoej3Y7Bsn4lda6GGh3bfnYDa2ktOlHdi8ENkahj8EFGRuvc0CV0WHsL/Dt+U0mKS0vSWT1e/WPATm5Qu2x70v+MAgN+Cw7H+zH2t8kvfaIK321fV+QjL3UH7sRn77RCZHgY/RFRkzt+LwUd/nsOViHh8tfUy0tUaaDQCI1ee0rvPnB1XsPuSYYuG6pKuYyXRs3djMGVTqM7y1kr9XSEDartrpbGfD5HpYfBDREXit+Bw9Pr+CI7fet7vJi45Hdsu5j6c/X//3cKoVadwLTK+QOdV62g56rPkiN7yZrnEMp1qeeDXYc2wakQLWFuaY/SzuXqIyLRwtBcRFQldLS1JaWqMXRNi0P7hjxNRw8M+3+fN0GSOynKwskBcSoZW/qi2vvj58C1pu3llF60y2XWqldnv59y0QCgt+P9HIlNk9L/cmTNnonnz5rC3t4e7uzv69OmDq1evysqkpKRgzJgxKFeuHOzs7NCvXz9ERsqbte/cuYPu3bvDxsYG7u7u+OSTT5CRof3BRUSmKyxK3pqT1cnY1U6pVTYmR98dQ2U8e+xlYW6GVlXLyfLe61QNE7vWxitNK2BOvwYI+7qrtBxFXhj4EJkuo//1Hjx4EGPGjMGxY8ewe/dupKenIzAwEImJz4evfvjhh/j333/x119/4eDBg3jw4AH69u0r5avVanTv3h1paWk4evQoVq5ciRUrVmDq1KnGri4RGVlSWgbe/yMEf2ZbyDMpTfd/XDaGPJBtrxvtjwldamnNqAwA0bl0is4pITUDQ349gY0h95Hx7LGXhZkCa0a1lJX7KLAmzM0UmPdqQ/Rv7gNLcwY0RGWBQrzoONI8PHr0CO7u7jh48CDatWuH2NhYuLm5Yc2aNXjllVcAAFeuXEHt2rURHByMli1bYvv27ejRowcePHgAD4/MJualS5diwoQJePToEZRK7f8V5hQXFwdHR0fExsbCwcGhMC+RiJ5JzVCj/ZwDiIjLXKIifFZ3AMDJ8Gi8ujQY9ioLXJgehMoTt2rte+GLQNhbPR85lVXGRmmOpDQ13mpfBZO61jaoHhP+Pi+tov7X2/54dWkwvB2tcHRSZ1x6EIfPN17AwtcaoVI52xe6XiIyvqL4/i70/+bExsYCAFxcMp+jnz59Gunp6QgICJDK1KpVCxUrVkRwcOZcG8HBwahfv74U+ABAUFAQ4uLiEBqqe4RGamoq4uLiZD9EVLQW7gmTAh8A2BkaAeD5elmddYyWAgCluRnsVLq7IHo5WgEArjyMR1yKYY++Qu4+lV5nndvcPLMncx1vB2x4tzUDH6IyrFCDH41Gg3HjxqF169aoV68eACAiIgJKpRJOTk6ysh4eHoiIiJDKZA98svKz8nSZOXMmHB0dpR8fHx8jXw0R5eXHAzdk22/9dhpfb72E34/dAQBpdfScfW8crC31DhlvVdUVAHDw2iM0+GIXLj9b8iI1Q43ZO66g8sSt+DvbkhgA0Njn+SrsWee2NOMjLSLKVKifBmPGjMHFixexdu3awjwNAGDSpEmIjY2Vfu7evZv3TkSUJyEEfgsOx/FnC45euBeLhFTDBx9kH0mVNdoq5zpZjxPkS0sAwLb32+LXYc20ynb97jAA4H+Hb0nB1sd/ncM32y4jKS0DGo2QHnllZ8/JCInomUIb6j527Fhs2bIFhw4dQoUKzxf+8/T0RFpaGmJiYmStP5GRkfD09JTKnDhxQna8rNFgWWVyUqlUUKn0L1pIRPmn1gh88tc5rA/JfHS0fFhzDF9xEgBwa2Y3va01LrZKRCdqd1DOWh5iVNsqWLgnTErPWiE9uzreDqjj7YDfjt3WeY49l+UjRJcduolyes4LACp2ZiaiZ4z+aSCEwNixY7Fhwwbs27cPvr6+svymTZvC0tISe/fuldKuXr2KO3fuwN/fHwDg7++PCxcuICoqSiqze/duODg4oE6dOsauMhHpsOnsfVT9bJsU+ACQAh8AOBme2a9GrRGoO3WHrBPz5rGtcfLz5/36stT0zJynx1ZlgROfdZbSPw2qpbceXetp/4dHCKFzZNbM7Vfw06GbWukA8IZ/Jb3nIKKyxegtP2PGjMGaNWuwadMm2NvbS310HB0dYW1tDUdHR4wcORLjx4+Hi4sLHBwc8N5778Hf3x8tW2YOQw0MDESdOnUwePBgzJkzBxEREZg8eTLGjBnD1h2iQhabnA4bpTk+WHs213I3HiWgha8LDl6LQmKOhUntrSzhaG2J9jXccPDaIwBAt/ryIMYh22Oo3ObMcbXT/pv3nbQtr8tAeSdrVHO3w8Frj9Cmmit6NvDKcx8iKhuMHvz8+OOPAIAOHTrI0pcvX45hw4YBABYsWAAzMzP069cPqampCAoKwg8//CCVNTc3x5YtW/DOO+/A398ftra2GDp0KGbMmGHs6hJRNsE3nmDgz8cMKrv2xB0MbFERvwVrP5ayfzZya+WIFjh3Nwbrz9zDR0E1ZWVU2QKelHT9q7oDwFvtq+CP43d0ztCsz49vNEGDCk6IT0mHrdKCa3ARkaTQ5/kpLpznhyh/Tt9+in4/HtVKb1PNFcE3n0CtY4HQWzO7ocfi/xD64PnUEitHtED7Gm4GnTPrUdnfb/ujWR7LSqg1Au/9cQbbLshHfFZ1s4WnoxWOXH8ipYVMeQnOtnnPB0ZEJU9RfH9zbS+iMu72k0R8tydM1rcny2vNfDD7lQY4dO0RhvyaOQjB2cYST58tNfHZhotS4LP+3VbwcLBCeSdrg899dGInhD6IyzPwAQBzMwVmvtxAFvz0aOCFRQMaw+zZaqRPE9MY9BBRnhj8EJVhGo1A+7kHtNJredqjd6PyGNGmMgCgbXVXKW9Mx2r4autlAMAfJ+5I6RVdbHT2z8mNt5M1vPMRLDnaWGLNm36Yt+sqhraqjN6NysvyGfgQkSEY/BCVYd/vv64z/aPAmnipzvOJRhUKBb5/vTHO3onBsFaVEZucjsX75PvmN/ApqFbVXLG+mmveBYmI9GDwQ1QGzd5xRWs25uw61tTus9OjgTd6NPAGkBkcHbj6CBfuZy5fU+vZEHYiIlPAWb+IypjUDHWugQ8AWBgwIeBfb/tLr5cNbvbC9SIiKips+SEqY2KTtRcHHdHaF00qOWHsmhB8GFDDoONYWZrj/BeBAAAHKy4dQUSmg8EPkYkRQuCrrZdRuZwNBvtXzvf+yw5qz4A8pUdtKBQKtKvhlq9AhkEPEZkiBj9EJmbZoZv45b/MxUJfblIBdqr8/Rn/79m+luYKTOlRBwG1PaQJABnMEFFZwD4/RMVECIF/Tt/DvadJ+dpv5vYr0uulefTdyen07Wjp9fYP2mGIf+V8DTUnIioNGPwQFZM9l6Pw0V/n0GneQUzbdBFdvzuMp3pWJM8yft1Z2ba+oer6TNkYKr2u5m6Xr32JiEoLBj9ExWRXaOZMxWlqDVYG38blh3GYla1VJ6fQB7E6Z2E21KP4VFx6mDkb86KBjQt8HCIiU8fgh6iIqTUC49aG4K/T97Ty1p26i0PPVkHP8iAmGZUnbkX3Rf9JacNaVZZed5i7X+e6WzndfJQgve5cy70ANSciKh0Y/BAVsX/O3MPGsw/05g/59QSyrzfcatY+rTLZh6OHP0nC9/uu47s9YUhK0171fN7Oq6g8cSteW5a5Wrufrwts89lJmoioNGHwQ1SE9l+JwvIj4XmW8520Ddci4/EgJlkr7/3O1eFoIx+VtWDPNSzYcw11pu7ElI0XodEIxCan48j1x1r9gpQW/LMnorKN//0jKiIX7sVi+IqT0vYgv4qY0qMO/jx1F0sP3MB3Axvj1aXBUv4Ha8+iRwMvaXtOvwZISsvAsNa+AIBOtdyx70qU1nl+O3Yb954mYf/VR2jk46SV/yQh907VRESlnUJkb18vReLi4uDo6IjY2Fg4ODgUd3WIsP7MPYz/85y0ffjTjvBxsZGVOXTtEYb8ekJr31FtffF59zqytJikNIxYcRJn7sTkqx77PmqPKm4c6UVEJVNRfH+z5YeoiOTsk1xex/w6/lXL6dy3UjlbrTQnGyV+G+mHljP3Ij5Fu69PdsuHNUdHdnImIgLA4IeoyKSrNdLrqT3qwMxMoVXG0twMV7/qgpqTd8jS+zfz0XlMW5UFLnwRBCEE/jx1F5FxqZi/+5qsTGAdD7Su5mqEKyAiKh0Y/BAVkYxnwU/Xep4Y0cZXbzmVhTlufNMN6WoNrCzNDTq2QqHAa80rIiwyXgp+qrnbYc/49i9ecSKiUobBD1ERSVNnPveyMM97tJW5mQLmZoYFPtl5ZXuU9nFgzXzvT0RUFjD4oRdy+vZTnAyPxui2VXQ+xqHnslp+LM0L7z7ZqSxw4vPOMFcoUM5OVWjnISIyZQx+qMCeJqah349HAQAeDiq83LiCLD81Q407T5JQ3cO+OKpXoiSkZkgLklqaFe48O+72VoV6fCIiU8fgh/ItLDIeE9dfwOnbT6W061GZSyfcfpKI9nMPoF0NN2mZhi/71MPglpWKpa5F5e/T92CjNEe3+l6y9NAHsfj92B38ceKOlJaQmvvILCIiKlyc6pXyRaMReHPVKVngAwCHwx4DANrPPQAAsvWppmy8WGT1Kw6RcSn4+K9zeHf1GaRlPB/RFZ2Yhu6L/pMFPgDgZs/HUURExYnBD+l17OYT3M+2vMKj+FRU+Wwbbj9J0ip7/l4sZu/QvyK5sefS/HLLJVSeuBWztl8x+rHz0vnbA6g8cStikjJnSv7r1F0pr9uiw7j9JBEAsP3iQ619g+p6YFS7KkVTUSIi0okzPJNOlx/Goet3hwEA17/uCgtzM9SbtlN6ZPNxYA1cvB+HHaERBh3v37FtUL+CY65l1BqBhJQMOFhb4ObjRIRFxmPuzqu48SgR73SoigldakllK0/cKr32cbHGoU86QqEwfkfiJwmpeOf3M+hc2x1DW1XGkeuPMXLlqXwfx9xMgQWvNUKvht5GryMRUWnCGZ6p2IQ/TpReT1x/AX0bl5f1VXmnQzWYPxvdtfJoOKZtDpXyannaw8rSHD4uNvj3XObq5T2//w+3ZnbTG6BcjYhH0MJDAICA2h7YczlSlv/jgRvoXt8LdbwccC0qXpZ3NzoZvpO2wV5lgT9Gt0S98rkHWYY6fy8GI1acwuOEVJwIj8bCPWHo36xC3jvm8ElQTYzpWM0odSIiohfHlh/Sad3JO5jwzwWdeSc+76w1oih7S0yXup5YOrgpAODNlae0ApnJ3WvjzbZVkKHWYMn+G1iwRz4jsT7+VcqhWWVnLN53XW+ZSuVscPCTjgYdT5+YpDSsPXkXs7brf4yXk7ONJea/1gjzd13DhfuxsryL04Ngp+L/M4iIDMGWHyoSD2KS0WrWPvi62mL1m37YdyUKk/V0UvZytNI5lNrdXoWo+FQAwHcDG0npywY3RZXPtsnKfrX1MrwcrfEoPsXgwAcAgm8+QfDNJ7K0Q590RLu5+6Xt20+SEJOUBicbpcHHzSlwwSHpWvRZN7olRqw4icQ0NQCgkY8TOtZ0R4cabnialI4/T93Fb8G3MbtfAwY+REQlDFt+yri70UloO2d/3gUBqCzMcG5aoM4lF+JS0hF6Pw5+vi5akx3++t8tzNhyKd91OzapM249TkTwzSdYtDdMK/+3kS3Qtrob4lPSUf+LXVJ6LU977BjXLt/nA4CfD93E19suy9Imdq2F2l4OGPpstfWsoftpGRpsvfAAwTee4Ks+9aG04PgBIqIXVRTf3wx+yrigBYdwNTJeb763oxXebFsFGiEwso1vgToVCyFw5PoTvPHLcb1lLMwUGN66Mka3q4rv94Whc20PtKvhJuX3WXIEZ+/GSNu/DG2GzrU9pO33/giR+hcBQPis7gbVTaMR+HrbZWiEgKudCnN3XpXl3/imm9S36WpEPJxsLOHhwEkEiYgKC4OfF8DgR7/HCalo9tUerfReDb2x+VkAMcivIio42yCwrgequtkZ5bzf7QmDRgh8l6MVZ8Xw5uhQ0z3P/Xt9/x/O38vsTxM6PQi2OR4nZe93tHZ0S7SsUi7PY05af0FrHh4A6F7fC9/2b2jwwqJERGQc7PNDhWL1Me0v+6yRWAteawQzBQpl2PgHAdUBABfux2LflSgAwPz+DQ0KfABg2eBmuBIRh/Y13HTWr3Mtd+x9dtwBy47hwMcdcPNxAjrV8tAqm67WwNLcTGfgAwCLBzbmWmVERKUUg58yKCIuWbb9dvuqUjBhXgRf+N+/3hiTN1xE+5pu6N2ovMH7eTpawdNR/yOnH99oihqTt0vbHeYdAJDZOdkvWyvQskM38M22K/B1tdV5nKH+lRj4EBGVYgx+yqB0deaTzk+71MQ72QKfomKjtMD81xoZ/bhKCzM08nGS9Q0CgIsP4tDC1wXf7rqG7/c/HyZ/K9tcRiFTXoKzbcFHiBERkeng8JR8ehibjI//Ooe70dpLPJiK+JR0AIC9lWWRBz6Fbe3ollpp+69EYcfFCFngk5OjtWVhVouIiEoQtvzkgxACUzaGYs/lSPx9+h5c7ZR4t0M1DG9d2WSCiKsR8dgZmjnpoINV6fv16+qg/N/1x4hNTs91Pz7mIiIqO0rft18ha1/DVZqx+HFCGmZsuQRHa0v0a5r/ZQ8K6rfgcPzy3y14Olrhh0FNkZiagZikdNQr7yAFYSnpavx86CaquduhSz1PCAFcfBCLXt8fkY5TzrZ0ri6+68N2OHErGk8T0/Dt7sxJFLNmXVYogO0ftIWVhTnGrTsLN3sVZvSuW5zVJSKiIsah7gVw50kS3v79NC49jJOlB9bxwIg2vmhc0Qm/Bd/GnegkDG/tq7NjbWRcCj7fcAHVPezxaVBNg1qOdlx8iJ8O3UTInRi9ZSo4W+Pe02S9+VlebVoBs/o1KJIOzsUp+/B3APhvQkdUcLYpptoQEVFeOM/PCyiKm7crNAKjfzttUNkmFZ1w5lnQYqeykC0SCgDvdKiqNwh6GJuMSw/itFYTt1WaS8srGKpFZReMC6iOVtVc87WfqZqy8SJ+O3YbANCxphuWD29RzDUiIqLcMPh5AUVx8zQaga+2XsavR24Z5Xir3/RD62quCLnzFC//cFRvuV4NvTHnlQZ4mpSGrecfws1eBZWFOd7+XR6I7f6wHb7Zdhn7rz5C38blMahlRTSt5GKUupqKuJR0NHi29MXlGV1greSkhUREJRmDnxdQHDM8azQCCWkZuBYRj3J2KqRmqHH7SRJ+PnQTp24/lcqpLMzQoaYb5r7aEEv2XcdPh24afI632lXBpG61C6P6pdb1qHhoBFDDw764q0JERHlg8PMCStryFo/iUxEWFY9WVbUfN3369zn8eeqe3n3LO1lj7eiWsFVZwIVz0RARUSnG5S1KETd7FdzsdY+u6lbfCxvPPkBahgYAMKxVZYxuVwXeTtZFWUUiIqIygS0/REREVGIUxfc3Z3gmIiKiMqVEBz9LlixB5cqVYWVlBT8/P5w4caK4q0REREQmrsQGP+vWrcP48eMxbdo0nDlzBg0bNkRQUBCioqKKu2pERERkwkps8DN//nyMGjUKw4cPR506dbB06VLY2Njg119/Le6qERERkQkrkcFPWloaTp8+jYCAACnNzMwMAQEBCA4O1rlPamoq4uLiZD9EREREOZXI4Ofx48dQq9Xw8PCQpXt4eCAiIkLnPjNnzoSjo6P04+PjUxRVJSIiIhNTIoOfgpg0aRJiY2Oln7t37xZ3lYiIiKgEKpGTHLq6usLc3ByRkZGy9MjISHh6eurcR6VSQaXSPYkgERERUZYS2fKjVCrRtGlT7N27V0rTaDTYu3cv/P39i7FmREREZOpKZMsPAIwfPx5Dhw5Fs2bN0KJFCyxcuBCJiYkYPnx4cVeNiIiITFiJDX5ee+01PHr0CFOnTkVERAQaNWqEHTt2aHWCJiIiIsoPru1FREREJQbX9iIiIiIyMgY/REREVKaU2D4/LyrraR5neiYiIjIdWd/bhdkrp9QGP/Hx8QDAmZ6JiIhMUHx8PBwdHQvl2KW2w7NGo8GDBw9gb28PhUJhtOPGxcXBx8cHd+/eZUfqPPBeGY73ynC8V4bhfTIc75XhiuJeCSEQHx8Pb29vmJkVTu+cUtvyY2ZmhgoVKhTa8R0cHPhHYiDeK8PxXhmO98owvE+G470yXGHfq8Jq8cnCDs9ERERUpjD4ISIiojKFwU8+qVQqTJs2jYuoGoD3ynC8V4bjvTIM75PheK8MV1ruVant8ExERESkC1t+iIiIqExh8ENERERlCoMfIiIiKlMY/BAREVGZYhLBz5IlS1C5cmVYWVnBz88PJ06ckPLeeustVK1aFdbW1nBzc0Pv3r1x5coVrWPcvn0b1tbWSEhIAAD89ddfqFWrFqysrFC/fn1s27ZNVn79+vUIDAxEuXLloFAocPbsWb318/X1xZ49e3DgwAH07t0bXl5esLW1RaNGjbB69Wqt8nmdWwiBqVOnwsvLC9bW1ggICEBYWJjWcbZu3Qo/Pz9YWlrCwsICFhYWcHd3R58+fXD16lVZ2YiICAwePBienp6wtbVFkyZN8M8//2gdMzk5Gba2trh+/ToePnyI119/HTVq1ICZmRnGjRunVf7nn39G27Zt4ezsDGdnZwQEBMh+P9l17NgR//vf/3Du3DkMHDgQPj4+sLa2Ru3atfHdd99plT9w4ACaNGkClUqFatWqYcWKFVplcntvhIeHQ6FQ6PyxtrbWea+io6Px3nvvoWbNmrC2tkbFihXx/vvvIzY2Vuvc2d9ToaGh6NevHypXrgyFQoGFCxdqlZ85cyaaN28Oe3t7vb+nLMXxnjpz5gxeeuklODk5oVy5cujZsye6du0Kb29vKBQKbNy4Ueu8ly9fRq9eveDo6AhbW1s0b94cd+7c0Xs9KSkpGDZsGOrXrw8LCwv06dNHq+z69evx0ksvwc3NDQ4ODvD398fOnTt13qfhw4dj8uTJCA8Px8iRI+Hr6wtra2tUrVoV06ZNQ1pamqz8+fPn0bZtW1hZWcHHxwdz5syR5Rvyezx06BB69uwpuy+60rL74osvUKtWLdja2kp/J8ePH9c6tin9/eV1zbldd25/tzdu3MDLL78s/f779++PyMjIUn+vhg0bpvU51aVLl1zvVRYhBLp27ar32Kb0WZXXd29un+t//fWXzjrqUuKDn3Xr1mH8+PGYNm0azpw5g4YNGyIoKAhRUVEAgKZNm2L58uW4fPkydu7cCSEEAgMDoVarZcfZtGkTOnbsCDs7Oxw9ehQDBw7EyJEjERISgj59+qBPnz64ePGiVD4xMRFt2rTB7Nmzc63f+fPn8fTpU7Rv3x5Hjx5FgwYN8M8//+D8+fMYPnw4hgwZgi1btkjlDTn3nDlzsGjRIixduhTHjx+Hra0tgoKCkJKSIpX5559/MHjwYAwfPhwtW7bE9OnTMXv2bOzevRvp6ekIDAxEYmKiVH7IkCG4evUqNm/ejAsXLqBv377o378/QkJCZNeze/duVKpUCdWqVUNqairc3NwwefJkNGzYUOf1HzhwAAMHDsT+/fsRHBwMHx8fBAYG4v79+7Jy0dHROHLkCHr27InTp0/D3d0dv//+O0JDQ/H5559j0qRJ+P7776Xyt27dQvfu3dGxY0ecPXsW48aNw5tvvin7EszrveHj44OHDx/KfqpVqwaVSoVDhw7pvFcPHjzAgwcPMG/ePFy8eBErVqzAjh07MHLkSK1rz/6eSkpKQpUqVTBr1ix4enrqvFcHDx7EmDFjcOzYMb2/J6B43lMPHjxAQEAAqlWrhuPHj2PHjh24ceMGwsPDsWTJEp3Xc+PGDbRp0wa1atXCgQMHcP78eUyZMgVWVlZ6r0etVsPa2hrvv/8+AgICdB730KFDeOmll7Bt2zacPn0aHTt2RM+ePbXeq2q1Glu2bEGvXr1w5coVaDQa/PTTTwgNDcWCBQuwdOlSfPbZZ1L5uLg4BAYGolKlSjh9+jTmzp2LL774AsuWLZPKGPJ7TExMRMOGDWX3RVdadjVq1MD333+PCxcu4L///kPlypURGBiIR48eycqZ0t9fXtes77o7duyo9+82MTERgYGBUCgU2LdvH44cOYK0tDT07NkTGo2mVN8rAOjSpYvs8+rVV1/N9TMuy8KFC3NdxsmUPqvy+u7V9bk+ffp02NnZoWvXrrneXxlRwrVo0UKMGTNG2lar1cLb21vMnDlTZ/lz584JAOL69euy9E6dOokff/xRCCFE//79Rffu3WX5fn5+4q233tI63q1btwQAERISovN8M2bMEK+99pre+nfr1k0MHz5c2s7r3BqNRnh6eoq5c+dK+TExMUKlUok//vhDCCFEenq6KF++vPjf//6n85xRUVECgDh48KCUZmtrK1atWiUr5+LiIn7++WdZ2ogRI8SECRO0jtm+fXvxwQcf6L3OLBkZGcLe3l6sXLlSlr5q1Srh5+end793331XdOzYUdr+9NNPRd26dWVlXnvtNREUFCRt5/e9IYQQjRo1EiNGjJC2dd2rnP7880+hVCpFenq6LD37eyq7SpUqiQULFug9Xl7nLo731E8//STc3d2FWq2Wypw/f14AEGFhYQKA2LBhg+wcr732mnjjjTfyvE591zN06FDRu3fvPPcXQog6deqI6dOny9IOHTokvLy8hEaj0bnPnDlzhK+vr7T9ww8/CGdnZ5GamiqlTZgwQdSsWVPn/ob8HnXdF11pOcXGxgoAYs+ePbJ0U/r7y86Qaxbi+XVn/71n/7vduXOnMDMzE7GxsVJ+TEyMUCgUYvfu3bJjlbZ7pevvwZDPuJCQEFG+fHnx8OFDvcc2lc+q7PL67s0u5+e6IUp0y09aWhpOnz4t+x+imZkZAgICEBwcrFU+MTERy5cvh6+vr2w195iYGPz333/o1asXACA4OFjrf51BQUE6j5mXzZs3o3fv3nrzY2Nj4eLiIm3nde5bt24hIiJCVsbR0RF+fn5SmTNnzuD+/fswMzND48aN4eXlha5du0rRc9YjmuznbdWqFdatW4fo6GhoNBqsXbsWKSkp6NChg1RGo9Fgy5YtuV5PXpKSkpCeni47N2D8+5Tf9wYAnD59GmfPnpW14ui6V7rq5uDgAAuL50vh5XxPFYS+cxfHeyo1NRVKpVK2iKC1tTUA4L///tOqg0ajwdatW1GjRg0EBQXB3d0dfn5+Opvc87qevGg0GsTHx+u8Tz179tT7P15d96ldu3ZQKpVSWlBQEK5evYqnT58WuH75lZaWhmXLlsHR0VHWSmFKf38FkZaWhh9++AEA0LdvXyk9+99tamoqFAqFbAI9KysrmJmZyd6HpfVeHThwAO7u7qhZsyZGjx6d52dcUlISXn/9dSxZskRvK44pfVYVhK7PdUOU6ODn8ePHUKvV8PDwkKV7eHggIiJC2v7hhx9gZ2cHOzs7bN++Hbt375Z9wG3btg0NGjSAt7c3gMz+L3kd0xD379/H+fPn9Ta1/fnnnzh58iSGDx8upeV17qx/cytz8+ZNAJnP0ydPnowtW7bA2dkZHTp0wOPHjzFu3Di0bt0a9erVk9UlPT0d5cqVg0qlwltvvYUNGzagWrVqUpljx44BAPz8/PJ1H7KbMGECvL29ZW/w1NRU7NixQ+8f39GjR7Fu3TqMHj1aStN3n+Li4pCcnGzweyO7X375BbVr10arVq0AZH6A6rpX2T1+/BhffvmlrG6A9nsqv/Sdu7jeU506dUJERATmzp2LtLQ0PH36FBMnTgQAPHz4UKseUVFRSEhIwKxZs9ClSxfs2rULL7/8Mvr27YuDBw8afD2GmDdvHhISEtC/f39Z+qZNm/S+p65fv47FixfjrbfektL03aesvMK2ZcsW2NnZwcrKCgsWLMDu3bvh6uoq5ZvS319+ZL/urP4l1atX1zp2REQEWrZsCVtbW0yYMAFJSUlITEzExx9/DLVaLXsflsZ71aVLF6xatQp79+7F7NmzsX//fqjVatl7JOvYWe/XDz/8EK1atco1ADGlz6qCyPm5bqgSHfwYatCgQQgJCcHBgwdRo0YN9O/fX9Y/JrcPyRexefNmtGnTBk5OTlp5+/fvx/Dhw/Hzzz+jbt26Rj1v1rPvzz//HP369ZP6PSkUCvTr1w8XL17E2rVrZftMmTIFMTEx2LNnD06dOoXx48ejf//+uHDhglRm06ZN6NGjh+x///kxa9YsrF27Fhs2bJD1+9i3bx/c3d113oeLFy+id+/emDZtGgIDAwt0XkMkJydjzZo1sv8djBkzRue9yhIXF4fu3bujTp06+OKLL2R5L/qe0nfu4npP1a1bFytXrsS3334LGxsbeHp6wtfXFx4eHjrfD1nvwd69e+PDDz9Eo0aNMHHiRPTo0QNLly416HoMsWbNGkyfPh1//vkn3N3dpfTLly/jwYMH6Ny5s9Y+9+/fR5cuXfDqq69i1KhRBTpvYcjqE3L06FF06dIF/fv3l/XdKK1/f9mvu2PHjgAy+9Xo4ubmhr/++gv//vsv7Ozs4OjoiJiYGDRp0kR2X0rjvRowYAB69eqF+vXro0+fPli1ahUAaPV1y7J582bs27dPZ4fl7ErbZ1V2uj7XDVWigx9XV1eYm5tr9fSPjIyUNfE5OjqievXqaNeuHf7++29cuXIFGzZsAJDZ1Jozkvf09MzzmIbYvHmzzjfVwYMH0bNnTyxYsABDhgyR5eV17qx/cyvj5eUFAKhTp46Ur1KpYGZmhpCQEOzfvx8VKlSQ8m7cuIHvv/8ev/76Kzp37oyGDRti2rRpaNasmawDnr7rMcS8efMwa9Ys7Nq1Cw0aNJDl6TvupUuX0LlzZ4wePRqTJ0+W5em7Tw4ODrC2tjb4vZHl77//RlJSkvT7GDt2LLZs2aJ1r7LEx8ejS5cusLe3x4YNG2BpaSnl6XpP5Udu5y6u9xQAvP7664iIiMD9+/fx5MkTfPHFF3j06BGqVKmiVR9XV1dYWFjI3oMAULt2bdlorxd5T61duxZvvvkm/vzzT62m8s2bN+Oll17S6lz94MEDdOzYEa1atZJ1ZAb036esvMJma2uLatWqoWXLlvjll19gYWGBX375Rco3pb+//Mh+3StXrgQArS/S7O/FwMBA3LhxA1FRUXj8+DF+++033L9/X/Y+LK33KrumTZtK5855bE9PT+zbtw83btyAk5OTNNoXAPr16yd1ZzC1z6r8yvm5nh8lOvhRKpVo2rQp9u7dK6VpNBrs3bsX/v7+OvcRQkAIgdTUVACZz1CdnZ1lz9b9/f1lxwQyRw7oO6YuCQkJ2L9/v1Zz44EDB9C9e3fMnj1b61GJIef29fWFp6enrExcXByOHz8ulWnatClUKpU09FAIgXfffRePHz/GJ598Al9fX9nxk5KSAEDrf0nm5ubS/+DDwsJw+/ZtvPTSSwbfgyxz5szBl19+iR07dqBZs2ayPCEE/v33X637FBoaio4dO2Lo0KH4+uuvtY6Z133K73vjl19+Qa9eveDq6oqxY8diw4YN2Ldvn9a9Ap6PClIqldi8ebPWF6yu95QhhBC5nrs431PZeXh4wM7ODuvWrYOVlZXO94RSqUTz5s21hr9eu3YNlSpVyvV6DPHHH39g+PDh+OOPP9C9e3et/E2bNmkd9/79++jQoYPUEprz/e7v749Dhw4hPT1dStu9ezdq1qwJZ2fnfNfxRWk0GulzytT+/gpKqVTKPrsA/X+3rq6ucHJywr59+xAVFSV90ZaVe5XVKnj37l0pLfu9mjhxIs6fP4+zZ89KPwCwYMECLF++HIDpfVblV9bnupubW/53zlf36GKwdu1aoVKpxIoVK8SlS5fE6NGjhZOTk4iIiBA3btwQ33zzjTh16pS4ffu2OHLkiOjZs6dwcXERkZGRQgghxowZI9577z3ZMY8cOSIsLCzEvHnzxOXLl8W0adOEpaWluHDhglTmyZMnIiQkRGzdulUAEGvXrhUhISHi4cOHQggh/vrrL1G/fn3Zcfft2ydsbGzEpEmTxMOHD6WfJ0+e5Ovcs2bNEk5OTmLTpk3i/Pnzonfv3sLX11ckJydLZT744ANRvnx5sXPnTjFw4EChVCqFk5OTuHz5snTepKQkIYQQaWlpolq1aqJt27bi+PHj4vr162LevHlCoVCIrVu3CiGEmDt3rujZs6fW/Q8JCREhISGiadOm4vXXXxchISEiNDRUVlelUin+/vtv2TXHx8cLIYQ4efKkcHZ2lo2UunDhgnBzcxNvvPGGbJ+oqCipzM2bN4WNjY345JNPxOXLl8WSJUuEubm52LFjh0HvjezCwsKEQqEQ27dvF++8845wdHQUBw4ckJ07617FxsYKPz8/Ub9+fXH9+nVZmYyMDL3vqdTUVOleeXl5iY8//liEhISIsLAwqUxe5y7u99TixYvF6dOnxdWrV8X3338vrKysxCeffCJCQkIEADF//nwREhIibt++LYQQYv369cLS0lIsW7ZMhIWFicWLFwtzc3Nx+PBhvdcjhBChoaEiJCRE9OzZU3To0EG6b1lWr14tLCwsxJIlS2TXHBMTI4QQIjIyUlhaWopHjx5J+9y7d09Uq1ZNdO7cWdy7d0+2X5aYmBjh4eEhBg8eLC5evCjWrl0rbGxsxE8//ZSv32N8fLxUJuu+HDlyRGzbtk3nvUpISBCTJk0SwcHBIjw8XJw6dUoMHz5cqFQqcfHiRSGEaf796boP2d8f+q7bwsJCKJVKvX+3v/76qwgODhbXr18Xv/32m3BxcRHjx4+Xzlsa71V8fLz4+OOPRXBwsLh165bYs2ePaNKkifD09DToMy4Lcoz2MsXPqry+e7Nk/1wviBIf/AiR+aFcsWJFoVQqRYsWLcSxY8eEEELcv39fdO3aVbi7uwtLS0tRoUIF8frrr4srV65I+/r4+GgNkRQic/hyjRo1hFKpFHXr1pWCgCzLly8XALR+pk2bJoQQ4o033hCff/65bJ+hQ4fq3Kd9+/b5OrdGoxFTpkwRHh4eQqVSic6dO4urV6/KyqSlpYmPPvpIuLu76zwnALF8+XKp/LVr10Tfvn2Fu7u7sLGxEQ0aNJANfW/Tpo3WsHchhM7jVqpUScqvVKlSrvdp8uTJYtCgQbJjTps2Lc/jCiHE/v37RaNGjYRSqRRVqlSRXU8Wfe+N7CZNmiR8fHyEWq3O817t379fb5lbt24JIXS/p7KGZeb2u8/r3MX9nho8eLBwcXERSqVSNGjQQEyaNEnnuYcOHSrt88svv4hq1aoJKysr0bBhQ7Fx40YpT9f1CKH/PZOlffv2uZ73f//7n2jdurXsmPr+XnP+/+7cuXOiTZs2QqVSifLly4tZs2bJ8g35Peb2HtFV5+TkZPHyyy8Lb29voVQqhZeXl+jVq5c4ceKEdExT/PvTdx+yfk+5XXduf7cTJkwQHh4ewtLSUlSvXl18++23sukMSuO9SkpKEoGBgcLNzU1YWlqKSpUqiVGjRomIiAiDPuOy34PswY8pflbl9d2bJfvnekGYRPBTUKdPnxaOjo4iLS3NqMdNT08XLi4u4vjx40Y9bnF59OiRsLCw0Pu/iRdRv359sW7dOqMft7jwPWWYwryenj17itmzZxv9uMWFf3+G470yHD+rclei+/y8qIyMDCxevFjWWdUYoqOj8eGHH6J58+ZGPW5xiY6Oxvz587WGIL6otLQ09OvX74WGOZc0fE8ZpjCvp02bNhg4cKDRj1tc+PdnON4rw/GzKncKIYQo7koQERERFZVS3fJDRERElBODHyIiIipTGPwQERFRmcLgh4iIiMoUBj9ERERUpjD4ISIiojKFwQ8RFZthw4ZBoVBAoVDA0tISHh4eeOmll/Drr79K684ZYsWKFQVeOZ6Iyh4GP0RUrLp06YKHDx8iPDwc27dvR8eOHfHBBx+gR48eyMjIKO7qEVEpxOCHiIqVSqWCp6cnypcvjyZNmuCzzz7Dpk2bsH37dqxYsQIAMH/+fNSvXx+2trbw8fHBu+++i4SEBACZK0kPHz4csbGxUivSF198AQBITU3Fxx9/jPLly8PW1hZ+fn44cOBA8VwoEZUYDH6IqMTp1KkTGjZsiPXr1wMAzMzMsGjRIoSGhmLlypXYt28fPv30UwBAq1atsHDhQjg4OODhw4d4+PAhPv74YwDA2LFjERwcjLVr1+L8+fN49dVX0aVLF4SFhRXbtRFR8ePyFkRUbIYNG4aYmBhs3LhRK2/AgAE4f/48Ll26pJX3999/4+2338bjx48BZPb5GTduHGJiYqQyd+7cQZUqVXDnzh14e3tL6QEBAWjRogW++eYbo18PEZkGi+KuABGRLkIIKBQKAMCePXswc+ZMXLlyBXFxccjIyEBKSgqSkpJgY2Ojc/8LFy5ArVajRo0asvTU1FSUK1eu0OtPRCUXgx8iKpEuX74MX19fhIeHo0ePHnjnnXfw9ddfw8XFBf/99x9GjhyJtLQ0vcFPQkICzM3Ncfr0aZibm8vy7OzsiuISiKiEYvBDRCXOvn37cOHCBXz44Yc4ffo0NBoNvv32W5iZZXZT/PPPP2XllUol1Gq1LK1x48ZQq9WIiopC27Zti6zuRFTyMfghomKVmpqKiIgIqNVqREZGYseOHZg5cyZ69OiBIUOG4OLFi0hPT8fixYvRs2dPHDlyBEuXLpUdo3LlykhISMDevXvRsGFD2NjYoEaNGhg0aBCGDBmCb7/9Fo0bN8ajR4+wd+9eNGjQAN27dy+mKyai4sbRXkRUrHbs2AEvLy9UrlwZXbp0wf79+7Fo0SJs2rQJ5ubmaNiwIebPn4/Zs2ejXr16WL16NWbOnCk7RqtWrfD222/jtddeg5ubG+bMmQMAWL58OYYMGYKPPvoINWvWRJ8+fXDy5ElUrFixOC6ViEoIjvYiIiKiMoUtP0RERFSmMPghIiKiMoXBDxEREZUpDH6IiIioTGHwQ0RERGUKgx8iIiIqUxj8EBERUZnC4IeIiIjKFAY/REREVKYw+CEiIqIyhcEPERERlSkMfoiIiKhM+T+pJRu1CMTuPQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[data['Name']=='AMZN'].plot(x='Date', y='Close', title='Volumen de transacciones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0025, -0.0130, -0.0065],\n",
      "        [ 0.0267,  0.0032,  0.0026],\n",
      "        [ 0.0014, -0.0098,  0.0069],\n",
      "        [ 0.0040, -0.0141, -0.0011],\n",
      "        [-0.0046, -0.0219, -0.0033],\n",
      "        [-0.0185, -0.0278, -0.0104],\n",
      "        [-0.0204, -0.0258, -0.0098],\n",
      "        [-0.0112, -0.0197, -0.0097],\n",
      "        [-0.0156, -0.0226, -0.0053],\n",
      "        [-0.0150, -0.0267, -0.0093],\n",
      "        [-0.0159, -0.0236, -0.0104],\n",
      "        [-0.0171, -0.0241, -0.0066],\n",
      "        [-0.0117, -0.0258, -0.0104],\n",
      "        [-0.0210, -0.0277, -0.0126],\n",
      "        [-0.0209, -0.0283, -0.0103],\n",
      "        [-0.0183, -0.0287, -0.0125],\n",
      "        [-0.0205, -0.0275, -0.0123],\n",
      "        [-0.0236, -0.0301, -0.0121],\n",
      "        [-0.0160, -0.0278, -0.0128],\n",
      "        [-0.0076, -0.0239, -0.0106],\n",
      "        [-0.0220, -0.0312, -0.0123],\n",
      "        [-0.0171, -0.0292, -0.0138],\n",
      "        [-0.0251, -0.0308, -0.0141],\n",
      "        [-0.0181, -0.0281, -0.0126],\n",
      "        [-0.0163, -0.0281, -0.0114],\n",
      "        [-0.0038, -0.0193, -0.0094],\n",
      "        [-0.0082, -0.0176, -0.0050],\n",
      "        [-0.0107, -0.0215, -0.0057],\n",
      "        [-0.0134, -0.0258, -0.0088],\n",
      "        [-0.0132, -0.0248, -0.0093],\n",
      "        [-0.0224, -0.0307, -0.0111],\n",
      "        [-0.0144, -0.0292, -0.0144],\n",
      "        [-0.0203, -0.0288, -0.0123],\n",
      "        [-0.0129, -0.0259, -0.0106],\n",
      "        [-0.0181, -0.0275, -0.0116],\n",
      "        [-0.0229, -0.0329, -0.0143],\n",
      "        [-0.0243, -0.0338, -0.0162],\n",
      "        [-0.0212, -0.0313, -0.0148],\n",
      "        [-0.0165, -0.0283, -0.0138],\n",
      "        [-0.0205, -0.0344, -0.0147],\n",
      "        [-0.0200, -0.0340, -0.0177],\n",
      "        [-0.0190, -0.0330, -0.0165],\n",
      "        [-0.0228, -0.0314, -0.0161],\n",
      "        [-0.0056, -0.0242, -0.0117],\n",
      "        [ 0.0020, -0.0273, -0.0091],\n",
      "        [-0.0199, -0.0399, -0.0226],\n",
      "        [-0.0311, -0.0412, -0.0201],\n",
      "        [-0.0279, -0.0407, -0.0227],\n",
      "        [-0.0299, -0.0432, -0.0242],\n",
      "        [-0.0307, -0.0449, -0.0253],\n",
      "        [-0.0348, -0.0475, -0.0267],\n",
      "        [-0.0336, -0.0457, -0.0262],\n",
      "        [-0.0268, -0.0431, -0.0262],\n",
      "        [-0.0306, -0.0479, -0.0260],\n",
      "        [-0.0330, -0.0499, -0.0296],\n",
      "        [-0.0336, -0.0498, -0.0293],\n",
      "        [-0.0365, -0.0493, -0.0297],\n",
      "        [-0.0299, -0.0481, -0.0285],\n",
      "        [-0.0321, -0.0519, -0.0314],\n",
      "        [-0.0215, -0.0432, -0.0284],\n",
      "        [-0.0164, -0.0358, -0.0220],\n",
      "        [-0.0277, -0.0450, -0.0238],\n",
      "        [-0.0290, -0.0478, -0.0288],\n",
      "        [-0.0317, -0.0501, -0.0289]])\n",
      "tensor([[0.0878, 0.0450, 0.0516],\n",
      "        [0.0450, 0.0516, 0.0491],\n",
      "        [0.0516, 0.0491, 0.0169],\n",
      "        [0.0491, 0.0169, 0.0193],\n",
      "        [0.0169, 0.0193, 0.0274],\n",
      "        [0.0193, 0.0274, 0.0261],\n",
      "        [0.0274, 0.0261, 0.0204],\n",
      "        [0.0261, 0.0204, 0.0162],\n",
      "        [0.0204, 0.0162, 0.0270],\n",
      "        [0.0162, 0.0270, 0.0324],\n",
      "        [0.0270, 0.0324, 0.0152],\n",
      "        [0.0324, 0.0152, 0.0216],\n",
      "        [0.0152, 0.0216, 0.0207],\n",
      "        [0.0216, 0.0207, 0.0180],\n",
      "        [0.0207, 0.0180, 0.0122],\n",
      "        [0.0180, 0.0122, 0.0303],\n",
      "        [0.0122, 0.0303, 0.0497],\n",
      "        [0.0303, 0.0497, 0.0220],\n",
      "        [0.0497, 0.0220, 0.0274],\n",
      "        [0.0220, 0.0274, 0.0120],\n",
      "        [0.0274, 0.0120, 0.0241],\n",
      "        [0.0120, 0.0241, 0.0283],\n",
      "        [0.0241, 0.0283, 0.0425],\n",
      "        [0.0283, 0.0425, 0.0334],\n",
      "        [0.0425, 0.0334, 0.0290],\n",
      "        [0.0334, 0.0290, 0.0266],\n",
      "        [0.0290, 0.0266, 0.0347],\n",
      "        [0.0266, 0.0347, 0.0229],\n",
      "        [0.0347, 0.0229, 0.0340],\n",
      "        [0.0229, 0.0340, 0.0271],\n",
      "        [0.0340, 0.0271, 0.0354],\n",
      "        [0.0271, 0.0354, 0.0246],\n",
      "        [0.0354, 0.0246, 0.0172],\n",
      "        [0.0246, 0.0172, 0.0169],\n",
      "        [0.0172, 0.0169, 0.0249],\n",
      "        [0.0169, 0.0249, 0.0380],\n",
      "        [0.0249, 0.0380, 0.0312],\n",
      "        [0.0380, 0.0312, 0.0323],\n",
      "        [0.0312, 0.0323, 0.0323],\n",
      "        [0.0323, 0.0323, 0.0228],\n",
      "        [0.0323, 0.0228, 0.0606],\n",
      "        [0.0228, 0.0606, 0.0937],\n",
      "        [0.0606, 0.0937, 0.0316],\n",
      "        [0.0937, 0.0316, 0.0264],\n",
      "        [0.0316, 0.0264, 0.0283],\n",
      "        [0.0264, 0.0283, 0.0278],\n",
      "        [0.0283, 0.0278, 0.0276],\n",
      "        [0.0278, 0.0276, 0.0175],\n",
      "        [0.0276, 0.0175, 0.0218],\n",
      "        [0.0175, 0.0218, 0.0372],\n",
      "        [0.0218, 0.0372, 0.0360],\n",
      "        [0.0372, 0.0360, 0.0299],\n",
      "        [0.0360, 0.0299, 0.0295],\n",
      "        [0.0299, 0.0295, 0.0240],\n",
      "        [0.0295, 0.0240, 0.0424],\n",
      "        [0.0240, 0.0424, 0.0315],\n",
      "        [0.0424, 0.0315, 0.0505],\n",
      "        [0.0315, 0.0505, 0.0620],\n",
      "        [0.0505, 0.0620, 0.0320],\n",
      "        [0.0620, 0.0320, 0.0322],\n",
      "        [0.0320, 0.0322, 0.0357],\n",
      "        [0.0322, 0.0357, 0.0278],\n",
      "        [0.0357, 0.0278, 0.0327],\n",
      "        [0.0278, 0.0327, 0.0343]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m         all_targets\u001b[38;5;241m.\u001b[39mappend(targets\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Concatenamos todos los batch para tener un solo tensor\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_targets, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Si es horizonte 1:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# all_preds: [N], all_targets: [N]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Si es horizonte > 1, puedes elegir un paso en particular o hacer promedio\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Ej: tomamos el primer paso:\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que tu modelo esté en modo eval\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# Iteramos sobre el test_dataloader\n",
    "with torch.no_grad():\n",
    "    for batch in data_module.test_dataloader():\n",
    "        features, targets = batch\n",
    "        # features: [batch_size, seq_len, 1] (o como sea tu input)\n",
    "        # targets: [batch_size, horizon] (o [batch_size] si es un horizonte 1)\n",
    "        \n",
    "        preds = model(features)  # [batch_size, horizon] o [batch_size]\n",
    "        \n",
    "        # Guardamos predicciones y targets\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "# Concatenamos todos los batch para tener un solo tensor\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Si es horizonte 1:\n",
    "# all_preds: [N], all_targets: [N]\n",
    "# Si es horizonte > 1, puedes elegir un paso en particular o hacer promedio\n",
    "# Ej: tomamos el primer paso:\n",
    "if len(all_preds.shape) > 1:  # horizonte > 1\n",
    "    all_preds = all_preds[:, 0]\n",
    "    all_targets = all_targets[:, 0]\n",
    "\n",
    "all_preds = all_preds.numpy()\n",
    "all_targets = all_targets.numpy()\n",
    "\n",
    "# Ahora graficamos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(all_targets, label='Real')\n",
    "plt.plot(all_preds, label='Predicción')\n",
    "plt.title('Comparación de Predicción vs Real (Test)')\n",
    "plt.xlabel('Índice de muestra')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Volume Mean: 0.06224386458458731\n",
      "Train Volume Variance: 0.003282136544897219\n",
      "Val Volume Mean: 0.024593598476296163\n",
      "Val Volume Variance: 0.0005386118807041858\n",
      "Test Volume Mean: 0.027790050447887682\n",
      "Test Volume Variance: 0.0003195052666290482\n"
     ]
    }
   ],
   "source": [
    "# Mean and variance for train set\n",
    "print(\"Train Volume Mean:\", data_module.train_df['Volume'].mean())\n",
    "print(\"Train Volume Variance:\", data_module.train_df['Volume'].var())\n",
    "\n",
    "# Mean and variance for val set\n",
    "print(\"Val Volume Mean:\", data_module.val_df['Volume'].mean())\n",
    "print(\"Val Volume Variance:\", data_module.val_df['Volume'].var())\n",
    "\n",
    "# Mean and variance for test set\n",
    "print(\"Test Volume Mean:\", data_module.test_df['Volume'].mean())\n",
    "print(\"Test Volume Variance:\", data_module.test_df['Volume'].var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR2ACT = {\n",
    "    'tanh' : nn.Tanh,\n",
    "    'sigmoid': nn.Sigmoid,\n",
    "    'relu' : nn.ReLU,\n",
    "    'gelu' : nn.GELU\n",
    "}\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of a Recurrent Neural Network\n",
    "\n",
    "    __init__()\n",
    "    input_size[int]: features per timestep, if > 1 is multivariate\n",
    "    hidden_size[int]: hidden size, normally between (64, 2056)\n",
    "    num_layers[int]: number of rnn stacked cells, if > 1 is DeepRNN, normally between (1, 8)\n",
    "    bidirectional[bool]: if the rnn is bidirectional\n",
    "    bias[bool]: if input linear layers have bias\n",
    "\n",
    "    forward()\n",
    "    x[torch.Tensor]: model input of size [batch_size, seq_len, input_size]\n",
    "    h[torch.Tensor]: initial hidden state of size [batch_size, seq_len, input_size], if None it will be zeros\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False, bias=False, activation='tanh', p_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.bias = bias\n",
    "        self.p_drop = p_drop\n",
    "\n",
    "        self.l2r = nn.ModuleList([self.rnn_layer(input_layer=(l==0)) for l in range(self.num_layers)]) # left to right RNN\n",
    "\n",
    "        if bidirectional:\n",
    "            self.r2l = nn.ModuleList([self.rnn_layer(input_layer=(l==0)) for l in range(self.num_layers)]) # right to left RNN\n",
    "\n",
    "        self.activation = STR2ACT[activation]() # tanh by default\n",
    "\n",
    "\n",
    "    def rnn_layer(self, input_layer=False):\n",
    "        return nn.ModuleDict({\n",
    "            'w_ih' : nn.Linear(self.input_size if input_layer else self.hidden_size, self.hidden_size, bias=self.bias),\n",
    "            'w_hh' : nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            'drop' : nn.Dropout(self.p_drop)\n",
    "        })\n",
    "    \n",
    "    def process_sequence(self, x, h, direction='l2r'):\n",
    "        \"\"\"\n",
    "        In deep RNNs (num_layers > 1), hidden state is propagated as:\n",
    "        - input hidden state of the next layer of the current timestep; h(l, t) -> h(l+1, t)\n",
    "        - input hidden state of the current layer of the next timestep; h(l, t) -> h(l, t+1)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(0)\n",
    "        layers = self.l2r if direction == 'l2r' else self.r2l\n",
    "\n",
    "        output = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t] # input\n",
    "            for l, layer in enumerate(layers):\n",
    "                # h[l] here is the lth hidden state for t-1\n",
    "                # when override it will be the lth hidden state for t\n",
    "                h[l] = self.activation(\n",
    "                    layer['w_ih'](x_t) + layer['w_hh'](h[l])\n",
    "                )\n",
    "                h[l] = layer['drop'](h[l]) # no dropout by default\n",
    "\n",
    "                x_t = h[l] # also, it will be the input for the l+1th layer of t\n",
    "            \n",
    "            output.append(h[-1]) # final hidden state for timestep t\n",
    "        \n",
    "        return torch.stack(output).transpose(0, 1) # [seq_len, batch_size, hidden_size] -> [batch_size, seq_len, hidden_size]\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        x = x.transpose(0, 1) # [batch_size, seq_len, input_size] -> [seq_len, batch_size, input_size]\n",
    "        batch_size = x.size(1)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            if h is None: # by default, hidden state is initialized to 0s\n",
    "                h = x.new_zeros((2, self.num_layers, batch_size, self.hidden_size)) # same device and dtype as x\n",
    "            \n",
    "            h_l2r, h_r2l = h[0], h[1] # if h is passed in bidirectional it is assumed that the format is [2, num_layers, batch_size, hidden_size]\n",
    "            \n",
    "            l2r_output = self.process_sequence(x, h_l2r, direction='l2r')\n",
    "            r2l_output = self.process_sequence(x.flip(dims=[-1]), h_r2l, direction='r2l')\n",
    "\n",
    "            r2l_output = r2l_output.flip(dims=[-1]) # flip to get left to right context\n",
    "\n",
    "            output = torch.cat([l2r_output, r2l_output], dim=-1) # [batch_size, seq_len, 2 * hidden_size]\n",
    "\n",
    "        else:\n",
    "            if h is None: # by default, hidden state is initialized to 0s\n",
    "                h = x.new_zeros((self.num_layers, batch_size, self.hidden_size)) # same device and dtype as x\n",
    "            \n",
    "            output = self.process_sequence(x, h, direction='l2r') # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    I_t (input_gate): how much of the input is added to the internal state\n",
    "    F_t (forget_gate): whether to keep the current memory state or flush it\n",
    "    O_t (output_gate): wheter the memory cell should influence the output\n",
    "    C_t (cell_gate): how much we take into account new data\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.layers = [self.lstm_layer(input_layer=(l==0))for l in range(num_layers)]\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid() \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def lstm_layer(self, input_layer=False):\n",
    "        \"\"\"\n",
    "        self.hidden_size * 4 because we use the same linear layer for\n",
    "        the four gates and then split the outputs\n",
    "        \"\"\"\n",
    "        return nn.ModuleDict({\n",
    "            'w_ih': nn.Linear(self.input_size if input_layer else self.hidden_size, self.hidden_size * 4, bias=False),\n",
    "            'w_hh': nn.Linear(self.hidden_size, self.hidden_size * 4),\n",
    "        })\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"\n",
    "        In deep LSTMs (num_layers > 1), hidden and internal state are propagated as:\n",
    "        - h(t, l) -> h(t+1, l); h(t, l) -> h(t, l+1)\n",
    "        - c(t, l) -> c(t+1, l); c(t, l) -> c(t, l+1)\n",
    "        \"\"\"\n",
    "        x = x.transpose(0, 1) # [batch_size, seq_len, input_size] -> [seq_len, batch_size, input_size]\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        if h is None: # by default, hidden and internal states are initialized to 0s\n",
    "            h = x.new_zeros((self.num_layers, batch_size, self.hidden_size)) # same device and dtype as x\n",
    "\n",
    "        h, c = (h, h) # at first, internal state is a copy of the hidden state\n",
    "\n",
    "        output = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "            for l, layer in enumerate(self.layers):\n",
    "                gates_proj = layer['w_ih'](x_t) + layer['w_hh'](h[l]) # [batch_size, hidden_size * 4]\n",
    "                input_gate, forget_gate, output_gate, cell_gate = gates_proj.chunk(4, dim=1)\n",
    "\n",
    "                input_gate = self.sigmoid(input_gate)\n",
    "                forget_gate = self.sigmoid(forget_gate)\n",
    "                output_gate = self.sigmoid(output_gate)\n",
    "                cell_gate = self.tanh(cell_gate)\n",
    "\n",
    "                c[l] = c[l] * forget_gate + input_gate * cell_gate\n",
    "                h[l] = self.tanh(c[l]) * output_gate\n",
    "                x_t = h[l]\n",
    "\n",
    "            output.append(h[-1])\n",
    "\n",
    "        return torch.stack(output).transpose(0, 1) # [seq_len, batch_size, hidden_size] -> [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.layers = nn.ModuleList([self.gru_layer(input_layer=(i==0)) for i in range(num_layers)])\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def gru_layer(self, input_layer=False):\n",
    "        \"\"\"\n",
    "        self.hidden_size * 2 because we use the same linear layer for\n",
    "        computing the reset and update gate\n",
    "\n",
    "        w_ch is the linear layer for computing the candidate hidden state\n",
    "        \"\"\"\n",
    "        return nn.ModuleDict({\n",
    "            'w_ig': nn.Linear(self.input_size if input_layer else self.hidden_size, self.hidden_size * 2, bias=False), # input to reset and update gates\n",
    "            'w_hg': nn.Linear(self.hidden_size, self.hidden_size * 2), # hidden state to reset and update gates\n",
    "            'w_ih': nn.Linear(self.input_size if input_layer else self.hidden_size, self.hidden_size, bias=False), # input to candidate hidden state\n",
    "            'w_gh': nn.Linear(self.hidden_size, self.hidden_size) # reset gate * hidden state to candidate hidden state\n",
    "        })\n",
    "    \n",
    "    def forward(self, x, h=None):\n",
    "        x = x.transpose(0, 1) # [batch_size, seq_len, input_size] -> [seq_len, batch_size, input_size]\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        if h is None: # by default, hidden and internal states are initialized to 0s\n",
    "            h = x.new_zeros((self.num_layers, batch_size, self.hidden_size)) # same device and dtype as x\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "            for l, layer in enumerate(self.layers):\n",
    "                gates_proj = layer['w_ig'](x_t) + layer['w_hg'](h[l])\n",
    "                reset_gate, update_gate = gates_proj.chunk(2, dim=1)\n",
    "\n",
    "                reset_gate = self.sigmoid(reset_gate)\n",
    "                update_gate = self.sigmoid(update_gate)\n",
    "\n",
    "                candidate_hidden_state = layer['w_gh'](reset_gate * h[l]) + layer['w_ih'](x_t)\n",
    "                candidate_hidden_state = self.tanh(candidate_hidden_state)\n",
    "\n",
    "                h[l] = ((1 - update_gate) * candidate_hidden_state) + (h[l] * update_gate)\n",
    "\n",
    "                x_t = h[l]\n",
    "            \n",
    "            output.append(h[-1])\n",
    "\n",
    "        return torch.stack(output).transpose(0, 1) # [seq_len, batch_size, hidden_size] -> [batch_size, seq_len, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers=num_layers, bidirectional=True, bias=True, activation='relu', p_drop=0.1)\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "\n",
    "x.size(), model(x).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
