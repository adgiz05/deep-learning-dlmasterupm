{"cells":[{"cell_type":"markdown","metadata":{"id":"eXl5PzoKDEmK"},"source":["<h1 align=\"center\">Deep Learning - Master in Deep Learning of UPM</h1>"]},{"cell_type":"markdown","metadata":{"id":"w3uHCp0VDEmM"},"source":["**IMPORTANTE**\n","\n","Antes de empezar debemos instalar PyTorch Lightning, por defecto, esto valdría:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SArzmQSlDEmO"},"outputs":[],"source":["!pip install pytorch-lightning"]},{"cell_type":"markdown","metadata":{"id":"O23KCJuqDEmQ"},"source":["Además, si te encuentras ejecutando este código en Google Collab, lo mejor será que montes tu drive para tener acceso a los datos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCtv-uFjDEmQ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"RLPAFe08DEmR"},"source":["<h1 align=\"center\">Atención - Introducción a los mecanismos de atención</h1>"]},{"cell_type":"markdown","metadata":{"id":"Bn-Fa_vQDEmR"},"source":["En esta sesión práctica estudiaremos los principales mecanismos de atennción:\n","- Definición de 'Atención'\n","    - $Q$ query, $K$ key y $V$ value.\n","    - Alineación\n","- Mecanismos de atención\n","    - Atención aditiva\n","    - Dot product attention\n","    - Scaled dot product self-attention\n","$$ $$\n"]},{"cell_type":"markdown","source":["## Carga del dataset\n","Se carga el dataset como en sesiones anteriores, no requiere hacer modificaciones. *Punto importante*: Las redes que incluyen mecanismos de atención pueden usarse también para secuencias."],"metadata":{"id":"nl2-gyQIHVRY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C73taijTDEmT"},"outputs":[],"source":["import datetime\n","\n","import torch\n","import torch.nn as nn\n","\n","import pytorch_lightning as pl\n","import torchmetrics\n","from pytorch_lightning import seed_everything\n","\n","import numpy as np\n","\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import matplotlib.pyplot as plt\n","\n","\n","DATA_PATH = 'data/sales.csv'\n","SEED = 42\n","seed_everything(seed=SEED) # Fijamos una semilla para reproducibilidad en los experimentos"]},{"cell_type":"markdown","metadata":{"id":"WZ2nhhgyDEmU"},"source":["Vamos practicar con un dataset que contiene registros a lo largo de 10 años (cada día) del número de ventas en una tienda. A considerar:\n","- Estamos ante un conjunto de datos **secuencial** (depende de t) y **univariable**.\n","- La variable _sold_ será a la vez feature y etiqueta, siendo nuestra \"X\" los pasados w registros de _sold_ y la etiqueta el futuro."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ew5mcGB2DEmV"},"outputs":[],"source":["sales_df = pd.read_csv(DATA_PATH)\n","sales_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWbsdELvDEmW"},"outputs":[],"source":["sales_df['date'] = pd.to_datetime(sales_df['date'], format='%Y-%m-%d')\n","sales_df.sort_values('date', inplace=True)\n","print(f\"Date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")"]},{"cell_type":"markdown","metadata":{"id":"AScwtwcZDEmX"},"source":["Para crear el dataset necesitamos definir tanto el tamaño de ventana como el de horizonte"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9zwv4EUDEmX"},"outputs":[],"source":["class SalesDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, w=10, h=1):\n","        self.data = df.drop('date', axis=1).values\n","        self.w = w\n","        self.h = h\n","\n","    def __len__(self):\n","        return len(self.data) - (self.w + self.h) + 1\n","\n","    def __getitem__(self, idx):\n","        features = self.data[idx:idx+self.w] # [i: i+w)\n","        target = self.data[idx+self.w: idx+self.w+self.h] # [i+w, i+w+h)\n","        return features, target"]},{"cell_type":"markdown","metadata":{"id":"dqcWKZuNDEmX"},"source":["Con ello ya podemos crear el DataModule de manera muy similar a como lo hacemos para datos tabulares.\n","\n","El único cambio importante reside en como hacemos el particionado del dataset. No podemos hacer un particionado random ya que los datos necesitan estar en orden, por ello, los splits serán diferentes ventanas de tiempo ordenadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fE7hB7SDEmX"},"outputs":[],"source":["class SalesDataModule(pl.LightningDataModule):\n","    def __init__(self, df, w=10, h=1, batch_size=16, val_size=0.2, test_size=0.2):\n","        super().__init__()\n","        self.train_df, self.val_df, self.test_df = self.sequential_train_val_test_split(df, val_size=val_size, test_size=test_size)\n","        self.scaler = self.normalize()\n","\n","        self.w = w\n","        self.h = h\n","\n","        self.batch_size = batch_size\n","\n","    def setup(self, stage=None):\n","        if stage == 'fit':\n","            self.train_dataset = SalesDataset(self.train_df, w=self.w, h=self.h)\n","            self.val_dataset = SalesDataset(self.val_df, w=self.w, h=self.h)\n","        elif stage == 'test':\n","            self.test_dataset = SalesDataset(self.test_df, w=self.w, h=self.h)\n","\n","    def sequential_train_val_test_split(self, df, val_size=0.2, test_size=0.2):\n","        # Aseguramos el formate de la fecha y ordenamos por ella\n","        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n","        df.sort_values('date', inplace=True)\n","\n","        # Calculamos los ínidices para hacer los splits\n","        n = len(df)\n","        train_end = int((1 - val_size - test_size) * n)\n","        val_end = int((1 - test_size) * n)\n","\n","        train = df.iloc[:train_end].copy()\n","        val = df.iloc[train_end:val_end].copy()\n","        test = df.iloc[val_end:].copy()\n","\n","        return train, val, test\n","\n","    def normalize(self):\n","        scaler = MinMaxScaler()\n","        self.train_df['sold'] = scaler.fit_transform(self.train_df['sold'].values.reshape(-1, 1))\n","        self.val_df['sold'] = scaler.transform(self.val_df['sold'].values.reshape(-1, 1))\n","        self.test_df['sold'] = scaler.transform(self.test_df['sold'].values.reshape(-1, 1))\n","        return scaler\n","\n","    def collate_fn(self, batch):\n","        features, targets = zip(*batch)\n","\n","        features = np.stack(features, axis=0)  # [batch_size, w, input_size]\n","        targets = np.stack(targets, axis=0)    # [batch_size, h, input_size]\n","\n","        features = torch.tensor(features, dtype=torch.float32)\n","        targets = torch.tensor(targets, dtype=torch.float32)\n","        return features, targets\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)"]},{"cell_type":"markdown","source":["## Atención\n","\n","La **atención** es un mecanismo que se puede incluir en redes neuronales que ayudará a la red a elegir qué partes de la entrada utilizar y seleccionar. Esta selección ocurre encontrando algún tipo de mecanismo que descubra cómo de alineados están la búsqueda (Query $Q$) y la clave (Key $K$). Queremos encontrar una función adecuada que nos diga cómo de importante es cada valor $V$.\n","\n","El concepto de **alineamiento** viene dado por la función de alineamiento:\n","$score(Q, K)$ que indica la importancia de cada cruce entre busqueda y clave. Estamos observando qué valores recuperar, de la misma manera que haríamos en una base de datos.\n","\n","### Algoritmo general\n","La atención aditiva será la primera en ser implementada. Computa el alineamiento entre la clave y el valor $(Q, V)$ respectivamente usando una capa lineal. Estas expresiones describen el alineamiento:\n","\n","1. **Computar Alineamiento**:\n","    $$e_{t,i} = score(Q, K)$$\n","\n","2. **Pesos de la atención**:\n","   $$\n","   \\alpha_{t,i} = \\frac{\\exp(e_{t,i})}{\\sum_{k=1}^{T} \\exp(e_{t,k})}\n","   $$\n","   - $T$ es la longitud del tamaño de secuencia.\n","\n","   Esta operación es equivalente a hacer una activación softmax `F.softmax(e_{t, i})`\n","\n","3. **Computar la salida**:\n","   $$\n","   c_t,i = \\alpha_{t,i} V_i\n","   $$\n","   donde $V_i$ es el valor de V en $i$ y $c_t$ es el vector de contexto (la salida) en el paso de tiempo $t$.\n","\n","### Implementacion\n","Vamos a implementar un modulo de atención genérico:"],"metadata":{"id":"1cIf3GkkMrFI"}},{"cell_type":"code","source":["class Attention(nn.Module):\n","    \"\"\"\n","    Modulo de atencion genérico\n","    hidden_dim[int]: tamaño de la representación\n","    \"\"\"\n","    def __init__(self, hidden_dim):\n","        super(Attention, self).__init__()\n","        self.hidden_dim = hidden_dim\n","\n","    def _score(self, q, k):\n","        # Q = Query, K = Key\n","        # Las dimensiones de Q y K tienen que ser compatibles!\n","        pass # Dependiendo de la funcion score tnedremos un mecanismo u otro\n","\n","    def forward(self, q, k, v):\n","        # Q = Query, K = Key, V = Value\n","        # Las dimensiones de Q, K y V tienen que ser compatibles!\n","        score = self._score(q, k)\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * v\n","        return context_vector, attention_weights"],"metadata":{"id":"pvwf4dwjOc23"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Módulos de atención"],"metadata":{"id":"nw9029HfHvo0"}},{"cell_type":"markdown","metadata":{"id":"oR4xBVwxDEmY"},"source":["### Aditiva\n","La atención aditiva será la primera en ser implementada. Computa el alineamiento entre la clave y el valor $(Q, V)$ respectivamente usando una capa lineal y una activación `tanh`. Estas expresiones describen el alineamiento:\n","\n","$$score(Q, K) = v_a^T tanh(W_a[Q, K])$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TsSGyX4SDEmY"},"outputs":[],"source":["class AdditiveAttention(nn.Module):\n","    \"\"\"\n","    Modulo de atencion\n","    hidden_dim[int]: tamaño de la representación\n","    \"\"\"\n","    def __init__(self, hidden_dim):\n","        super(AdditiveAttention, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n","        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.V = nn.Linear(hidden_dim, 1)\n","    def _score(self, q, k):\n","        # Q = Query, K = Key\n","        # Las dimensiones de Q y K tienen que ser compatibles!\n","        # Mecanismo de la atencion aditiva\n","        return self.V(torch.tanh(self.W1(q) + self.W2(k)))\n","\n","    def forward(self, q, k, v):\n","        # Q = Query, K = Key, V = Value\n","        # Las dimensiones de Q, K y V tienen que ser compatibles!\n","        score = self._score(q, k) # Q[batch_size; seq_len, hidden_dim]\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * v # Una atencion para cada elem. de la secuencia\n","        return context_vector, attention_weights #C[batch_size; seq_len; hidden_dim] // #A[batch_size; seq_len]"]},{"cell_type":"code","source":["with torch.no_grad():\n","  dummy = AdditiveAttention(16)\n","  X = torch.rand(1, 8, 16)\n","  print(dummy(X, X, X))"],"metadata":{"id":"944QCiz4VDdm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### General\n","La atención general es la siguiente en ser implementada. Computa el alineamiento como dos productos de matrices siguiendo la expresión:\n","$$score(Q, K) = Q^TW_aK $$"],"metadata":{"id":"N-cw8Fk5RM5N"}},{"cell_type":"code","source":["class GeneralAttention(nn.Module):\n","    def __init__(self, query_dim, key_dim):\n","        super(GeneralAttention, self).__init__()\n","        self.W_a = nn.Parameter(torch.randn(query_dim, key_dim))\n","\n","    def _score(self, q, k):\n","        # Q = Query, K = Key\n","        # Las dimensiones de Q y K tienen que ser compatibles!\n","        # Mecanismo de la atencion general\n","        left = torch.matmul(q, self.W_a)\n","        return torch.matmul(left, k.transpose(-2, -1))\n","\n","    def forward(self, q, k, v):\n","        # Q = Query, K = Key, V = Value\n","        # Las dimensiones de Q, K y V tienen que ser compatibles!\n","        score = self._score(q, k) #C[batch_size; seq_len; hidden_dim]\n","        attention_weights = torch.softmax(score, dim=1)\n","        # Cuidado, esto es el producto matricial!\n","        context_vector = torch.matmul(attention_weights, v)\n","        return context_vector, attention_weights #C[batch_size; seq_len; hidden_dim] // #A[batch_size; seq_len; seq_len]"],"metadata":{"id":"Jo4SKL_FR9Hx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  dummy = GeneralAttention(16,16)\n","  X = torch.rand(1, 8, 16)\n","  print(dummy(X, X, X))"],"metadata":{"id":"i-uZQynwWPcc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scaled Dot Product\n","Este mecanismo es frecuentemente utilizado en redes modernas (transformers).Computa el alineamiento como el producto matricial entre clave y búsqueda, después escala mediante la dimensión:\n","$$score(Q, K) = \\frac{QK^T}{\\sqrt{d_K}} $$\n","En este caso $d_K$ es la dimensión de la clave."],"metadata":{"id":"y7QUtZ2gMLAW"}},{"cell_type":"code","source":["class ScaledDotProductAttention(nn.Module):\n","    def __init__(self):\n","        super(ScaledDotProductAttention, self).__init__()\n","\n","    def _score(self, q, k):\n","        # Q = Query, K = Key\n","        # Las dimensiones de Q y K tienen que ser compatibles!\n","        # Mecanismo de la atencion general\n","        return torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(q.size(-1))\n","\n","    def forward(self, q, k, v):\n","        # Q = Query, K = Key, V = Value\n","        # Las dimensiones de Q, K y V tienen que ser compatibles!\n","        score = self._score(q, k) #C[batch_size; seq_len; hidden_dim]\n","        attention_weights = torch.softmax(score, dim=1)\n","        # Cuidado, esto es el producto matricial!\n","        context_vector = torch.matmul(attention_weights, v)\n","        return context_vector, attention_weights #C[batch_size; seq_len; hidden_dim] // #A[batch_size; seq_len; seq_len]"],"metadata":{"id":"FlNkQIS2UIC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  dummy = ScaledDotProductAttention()\n","  X = torch.rand(1, 8, 16)\n","  print(dummy(X, X, X))"],"metadata":{"id":"yr8HwZqLYI2_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LSTM con atencion\n","Vamos a darle a una LSTM la capacidad de tener (auto-)atención en su última salida. Inyectamos uno de los módulos de atención a la Lstm. Un ejemplo con el SDPA (Scaled dot-product attention):"],"metadata":{"id":"oxEeqKMVU5Yl"}},{"cell_type":"code","source":["class LSTMAttentionRegressor(nn.Module):\n","    \"\"\"\n","    LSTM Regressor model\n","    h[int]: horizonte de predicción\n","    input_size[int]: variables de la serie temporal\n","    hidden_size[int]: tamaño de las capas ocultas de la RNN\n","    num_layers[int]: número de capas de la RNN (si > 1, stacking de células RNN)\n","    batch_first[bool]: si el batch_size es la primera dimensión\n","    p_drop[float]: probabilidad de dropout\n","    \"\"\"\n","    def __init__(self,  h=1,\n","                 input_size=1,\n","                 hidden_size=64,\n","                 num_layers=1,\n","                 batch_first=True,\n","                 p_drop=0.0,\n","                 enable_attention=True):\n","        super(LSTMAttentionRegressor, self).__init__()\n","        self.lstm = nn.LSTM(input_size=input_size,\n","                            hidden_size=hidden_size,\n","                            num_layers=num_layers,\n","                            batch_first=batch_first,\n","                            dropout=p_drop,\n","                            )\n","        self.sdpa = ScaledDotProductAttention()\n","        self.fc = nn.Linear(hidden_size, h)\n","        self.enable_attention = enable_attention\n","\n","    def forward(self, x):\n","        x, _ = self.lstm(x)\n","        if self.enable_attention:\n","          x, _ = self.sdpa(x, x, x)\n","        output = self.fc(x[:, -1, :]) # Elegir la última salida\n","        return output #out[batch_size; h]"],"metadata":{"id":"4A3HD1TeU4py"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  dummy = LSTMAttentionRegressor(h=2, input_size=16, hidden_size=16, num_layers=1)\n","  X = torch.rand(4, 8, 16)\n","  print(dummy(X).shape)"],"metadata":{"id":"o-cunUbFaNbq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-1ixBMEDEmZ"},"source":["Vamos a declarar dos redes idénticas, una de ellas con un mecanismo de atención, y otra sin dicho mecanismo.\n","Probad a cambiar el tamaño de ventana comparando como crece el número de parámetros necesarios para modelar los datos!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MN2OXyyiDEmZ"},"outputs":[],"source":["input_size = 3\n","hidden_size = 64\n","batch_first = True\n","num_layers = 1\n","batch_size = 64\n","w = 10\n","h = 2\n","\n","pooling = 'last'\n","\n","lstm_no_att = LSTMAttentionRegressor(h=h,\n","                                     input_size=input_size,\n","                                     hidden_size=hidden_size,\n","                                     num_layers=num_layers,\n","                                     batch_first=batch_first,\n","                                     )\n","lstm_w_att = LSTMAttentionRegressor(h=h,\n","                                     input_size=input_size,\n","                                     hidden_size=hidden_size,\n","                                     num_layers=num_layers,\n","                                     batch_first=batch_first,\n","                                     enable_attention=True,\n","                                    )\n","x = torch.randn(batch_size, w, input_size)\n","\n","def stats(model, x):\n","    name = model.__class__.__name__\n","    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    params = sum([np.prod(p.size()) for p in model_parameters])\n","    print(f'Model: {name}')\n","    print(f'Model Parameters: {params}')\n","    print(f'Model Output Size: {model(x).size()}', end='\\n\\n')\n","\n","stats(lstm_no_att, x)\n","stats(lstm_w_att, x) # Esta vez nuestros modelos son identicos, salvo la atencion!"]},{"cell_type":"markdown","source":["## **EXTRA**: LSTM (con atencion entrenable)\n","Se puede entrenar parte de la atencion para mejorar el entendimiento usando matrices de pesos.\n","\n","Usala con el codigo anterior"],"metadata":{"id":"lBrjxXebj7_4"}},{"cell_type":"code","source":["class LSTMTrainableAttentionRegressor(nn.Module):\n","    \"\"\"\n","    LSTM Regressor model\n","    h[int]: horizonte de predicción\n","    input_size[int]: variables de la serie temporal\n","    hidden_size[int]: tamaño de las capas ocultas de la RNN\n","    num_layers[int]: número de capas de la RNN (si > 1, stacking de células RNN)\n","    batch_first[bool]: si el batch_size es la primera dimensión\n","    p_drop[float]: probabilidad de dropout\n","    \"\"\"\n","    def __init__(self,  h=1,\n","                 input_size=1,\n","                 hidden_size=64,\n","                 num_layers=1,\n","                 batch_first=True,\n","                 p_drop=0.0,\n","                 enable_attention=True):\n","        super(LSTMTrainableAttentionRegressor, self).__init__()\n","        self.lstm = nn.LSTM(input_size=input_size,\n","                            hidden_size=hidden_size,\n","                            num_layers=num_layers,\n","                            batch_first=batch_first,\n","                            dropout=p_drop,\n","                            )\n","        self.sdpa = ScaledDotProductAttention()\n","        self.Qw = nn.Linear(hidden_size, hidden_size)\n","        self.Kw = nn.Linear(hidden_size, hidden_size)\n","        self.Vw = nn.Linear(hidden_size, hidden_size)\n","        self.fc = nn.Linear(hidden_size, h)\n","        self.enable_attention = enable_attention\n","\n","    def forward(self, x):\n","        x, _ = self.lstm(x)\n","        if self.enable_attention:\n","          x, _ = self.sdpa(self.Qw(x), self.Kw(x), self.Vw(x))\n","        output = self.fc(x[:, -1, :]) # Elegir la última salida\n","        return output #out[batch_size; h]"],"metadata":{"id":"AVvkW1CPj7LW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Entrenamiento\n","Vamos a hacer el entrenamiento, definiendo el modulo de lighting y el resto de detalles faltantes para completar el proceso."],"metadata":{"id":"pt6GsigfgY3n"}},{"cell_type":"code","source":["class SalesPredictor(pl.LightningModule):\n","    def __init__(self, model, learning_rate=1e-3):\n","        super().__init__()\n","        self.save_hyperparameters() # guardamos la configuración de hiperparámetros\n","        self.learning_rate = learning_rate\n","        self.model = model\n","        self.criterion = nn.MSELoss()\n","        self.r2 = torchmetrics.R2Score()\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def compute_batch(self, batch, split='train'):\n","        inputs, targets = batch\n","        output = self(inputs)\n","\n","        preds = output.view(-1)\n","        targets = targets.view(-1)\n","\n","        loss = self.criterion(preds, targets)\n","        self.log_dict(\n","            {\n","                f'{split}_loss': loss,\n","                f'{split}_r2': self.r2(preds, targets),\n","            },\n","            on_epoch=True, prog_bar=True)\n","\n","        return loss\n","\n","    def training_step(self, batch, batch_idx):\n","        return self.compute_batch(batch, 'train')\n","\n","    def validation_step(self, batch, batch_idx):\n","        return self.compute_batch(batch, 'val')\n","\n","    def test_step(self, batch, batch_idx):\n","        return self.compute_batch(batch, 'test')\n","\n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate) # self.parameters() son los parámetros del modelo"],"metadata":{"id":"dDTLcE8pgR50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bucle de entrenamiento"],"metadata":{"id":"jp4kq1lmidvQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gy4p_UO3DEmb"},"outputs":[],"source":["# Parámetros\n","SAVE_DIR = f'lightning_logs/sales/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}'\n","w = 50\n","h = 3\n","batch_size = 64\n","num_layers = 1\n","hidden_size = 128\n","learning_rate = 1e-3\n","p_drop = 0.2\n","\n","# DataModule\n","data = pd.read_csv(DATA_PATH)\n","data_module = SalesDataModule(data, w=w, h=h, batch_size=batch_size)\n","\n","# Model (Probad a descomentar uno u otro)\n","#lstm = LSTMTrainableAttentionRegressor(...) # Usa esta otra definicion mas adelante\n","lstm = LSTMTrainableAttentionRegressor(h=h,\n","                              input_size=1,\n","                              hidden_size=hidden_size,\n","                              num_layers=num_layers,\n","                              batch_first=True,\n","                              enable_attention=True, # Cambia a false para probar que ocurre!\n","                              )\n","# model = MLPRegressor(w=w, h=h, input_size=1, hidden_size=hidden_size)\n","\n","# LightningModule\n","module = SalesPredictor(lstm, learning_rate=learning_rate)\n","\n","# Callbacks\n","early_stopping_callback = pl.callbacks.EarlyStopping(\n","    monitor='val_loss', # monitorizamos la pérdida en el conjunto de validación\n","    mode='min',\n","    patience=5, # número de epochs sin mejora antes de parar\n","    verbose=False, # si queremos que muestre mensajes del estado del early stopping\n",")\n","model_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    monitor='val_loss', # monitorizamos la pérdida en el conjunto de validación\n","    mode='min', # queremos minimizar la pérdida\n","    save_top_k=1, # guardamos solo el mejor modelo\n","    dirpath=SAVE_DIR, # directorio donde se guardan los modelos\n","    filename=f'best_model' # nombre del archivo\n",")\n","\n","callbacks = [early_stopping_callback, model_checkpoint_callback]\n","\n","# Loggers\n","csv_logger = pl.loggers.CSVLogger(\n","    save_dir=SAVE_DIR,\n","    name='metrics',\n","    version=None\n",")\n","\n","loggers = [csv_logger] # se pueden poner varios loggers (mirar documentación)\n","\n","# Trainer\n","trainer = pl.Trainer(max_epochs=50, accelerator='cpu', callbacks=callbacks, logger=loggers)\n","\n","trainer.fit(module, data_module)\n","results = trainer.test(module, data_module)"]},{"cell_type":"markdown","metadata":{"id":"mvMyoxtjDEmb"},"source":["### Visualizacion\n","Visualicemos con Matplotlib como están ajustando las predicciones del modelo a la realidad. Cuidado, el modelo de atencion no tiene por que ser mejor que el modelo sin atención. La atención es principalmente beneficiosa en problemas más complejos!"]},{"cell_type":"code","source":["all_preds = []\n","all_targets = []\n","\n","# Iteramos sobre el test_dataloader\n","with torch.no_grad():\n","    for batch in data_module.test_dataloader():\n","        features, targets = batch\n","        # features: [batch_size, seq_len, input_size]\n","        # targets: [batch_size, horizon] (o [batch_size] si es un horizonte 1)\n","        features = features.to(module.device)\n","        targets = targets.to(module.device)\n","\n","        preds = module(features)  # [batch_size, horizon] o [batch_size]\n","\n","        # Guardamos predicciones y targets\n","        all_preds.append(preds.cpu())\n","        all_targets.append(targets.cpu())\n","\n","# Concatenamos todos los batch para tener un solo tensor\n","# Si es horizonte > 1, puedes elegir un paso en particular o hacer promedio\n","# Ej: tomamos el primer paso:\n","all_preds = torch.cat(all_preds, dim=0)[:, 0]\n","all_targets = torch.cat(all_targets, dim=0)[:, 0]\n","\n","# Utilizamos el scaler inverso para obtener los valores originales\n","# all_preds = dm.scaler_test.inverse_transform(all_preds.reshape(-1, 1)).flatten()\n","# all_targets = dm.scaler_test.inverse_transform(all_targets.reshape(-1, 1)).flatten()\n","\n","# Ahora graficamos\n","plt.figure(figsize=(10, 6))\n","plt.plot(all_targets, label='Real')\n","plt.plot(all_preds, label='Predicción')\n","plt.title('Comparación de Predicción vs Real (Test)')\n","plt.xlabel('Índice de muestra')\n","plt.ylabel('Valor')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"syOigRv9h8cy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_preds = []\n","all_targets = []\n","\n","# Iteramos sobre el test_dataloader\n","with torch.no_grad():\n","    for batch in data_module.test_dataloader():\n","        features, targets = batch\n","        # features: [batch_size, seq_len, input_size]\n","        # targets: [batch_size, horizon] (o [batch_size] si es un horizonte 1)\n","        features = features.to(module.device)\n","        targets = targets.to(module.device)\n","\n","        preds = module(features)  # [batch_size, horizon] o [batch_size]\n","\n","        # Guardamos predicciones y targets\n","        all_preds.append(preds.cpu())\n","        all_targets.append(targets.cpu())\n","\n","# Concatenamos todos los batch para tener un solo tensor\n","# Si es horizonte > 1, puedes elegir un paso en particular o hacer promedio\n","# Ej: tomamos el primer paso:\n","all_preds = torch.cat(all_preds, dim=0)[:, 0]\n","all_targets = torch.cat(all_targets, dim=0)[:, 0]\n","\n","# Utilizamos el scaler inverso para obtener los valores originales\n","# all_preds = dm.scaler_test.inverse_transform(all_preds.reshape(-1, 1)).flatten()\n","# all_targets = dm.scaler_test.inverse_transform(all_targets.reshape(-1, 1)).flatten()\n","\n","# Ahora graficamos\n","plt.figure(figsize=(10, 6))\n","plt.plot(all_targets, label='Real')\n","plt.plot(all_preds, label='Predicción')\n","plt.title('Comparación de Predicción vs Real (Test)')\n","plt.xlabel('Índice de muestra')\n","plt.ylabel('Valor')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"3I2tj7tvmLJf"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"gpuType":"T4"}},"nbformat":4,"nbformat_minor":0}