{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRUKZPLHtlc6idPYsGKPMj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tema 4: Logging & Inference"],"metadata":{"id":"90rDx7aR9NY_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0ec2rnj9MfT"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms\n","from torchvision.transforms import Lambda\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import os\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n","from sklearn.preprocessing import label_binarize\n","import seaborn as sns"]},{"cell_type":"markdown","source":["### 1. Seleccionar GPU"],"metadata":{"id":"QcMQfkH4d0Uz"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Usando dispositivo: {device}\")"],"metadata":{"id":"y4zdcUnYwTN1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Conectar con Google Drive\n","\n","Para poder guardar los modelos."],"metadata":{"id":"1P5LEVg_d24K"}},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJXkaRhqEGfQ","executionInfo":{"status":"ok","timestamp":1732995032155,"user_tz":-60,"elapsed":1338,"user":{"displayName":"helena liz","userId":"14461101084112642621"}},"outputId":"3187291a-378a-46db-8f77-55e0ed6d1dcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## 3. Crear el dataset y dataloader para el conjunto de Fashion MNIST."],"metadata":{"id":"YySrICCVd_F6"}},{"cell_type":"markdown","source":["### Función Transform"],"metadata":{"id":"8czCS0TteiCo"}},{"cell_type":"code","source":["transform = transforms.Compose([\n","    ### CÓDIGO ###\n","\n","])"],"metadata":{"id":"4b_9bO3D9VJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset"],"metadata":{"id":"eHNewTiqekps"}},{"cell_type":"code","source":["full_train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n","test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, transform=transform, download=True)"],"metadata":{"id":"zNmRao7d9Wue"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dividir el conjunto de train, entre train y validación (80 y 20% respectivamente).\n","\n","Para ello utilizar ***random_split*** de torch."],"metadata":{"id":"ulAqZXgxem6d"}},{"cell_type":"code","source":["train_size = int(0.8 * len(full_train_dataset))\n","val_size = len(full_train_dataset) - train_size"],"metadata":{"id":"mwBHouPT9XI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])"],"metadata":{"id":"I6R095zW9YhA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Crear una función collate que aplane las muestras y devuelva por separado las muestras y las etiquetas."],"metadata":{"id":"jNz9rm3ve_Hm"}},{"cell_type":"code","source":["def flatten_batch(data):\n","\n","### CÓDIGO ###\n","\n","    return images, labels_collate"],"metadata":{"id":"dHMK5VmQ9avY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Crear el Dataloader"],"metadata":{"id":"Yu6xlSZqe8EO"}},{"cell_type":"code","source":["train_loader = DataLoader()\n","val_loader = DataLoader()\n","test_loader = DataLoader()"],"metadata":{"id":"9OwU5RF99b-A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Crear el modelo de MLP\n","\n","Se puede utilizar la clase que hemos creado en otras sesiones de la asignatura."],"metadata":{"id":"If31WAvHfICx"}},{"cell_type":"code","source":["class MLP_pytorch(nn.Module):\n","    def __init__(self, input_shape=150*150, n_classes=10):\n","        super().__init__()\n","\n","### CÓDIGO ###\n","\n","    def forward(self, x):\n","        # Forward pass\n","\n","### CÓDIGO ###\n","\n","        return x"],"metadata":{"id":"bgD9axPz9ieM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Crear una instancia del modelo y pasarlo a GPU"],"metadata":{"id":"oN-RcCh1fTeK"}},{"cell_type":"code","source":["model = ### CÓDIGO ###"],"metadata":{"id":"K9n8E8-l9k3o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Crear las funciones para:\n","\n","* model_checkpoint: que guarde el mejor modelo, utilizando el loss de validación.\n","* plot_progress: una función que en cada época guarde una visualización con las gráficas de loss y accuracy para entrenamiento y validación. Guardalo en PDF.\n","* Guardar el loss y el accuracy de cada época en un archivo csv."],"metadata":{"id":"uuwmT022fXrU"}},{"cell_type":"code","source":["def model_checkpoint(val_loss,epoch,model,optimizer,checkpoint_path,best_model_path):\n","\n","### CÓDIGO ###\n","\n","def plot_progress(train_loss_history,val_loss_history,train_acc_history,val_acc_history,plot_path):\n","\n","### CÓDIGO ###\n","\n","    plt.close(fig)\n","\n","\n","def save_results(epoch,train_loss,train_acc,val_loss,val_acc,csv_path):\n","    header = \"epoch,train_loss,train_acc,val_loss,val_acc\\n\"\n","    data = f\"### CÓDIGO ###\\n\"\n","\n","    file_exists = os.path.exists(csv_path)\n","\n","    with open(csv_path, mode='a') as file:\n","\n","        if not file_exists or os.stat(csv_path).st_size == 0:\n","            file.write(header)\n","        ### CÓDIGO ###"],"metadata":{"id":"JVg_ot5h9ljx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Entrenar el modelo.\n","\n","Definir todas las variables necesarias para:\n","\n","* Que se guarden en un directorio \"results\":\n","  * el mejor modelo basandose en el loss.\n","  * el checkpoint del modelo: época, model_state_dict, optimizer_state_dict y loss\n","  * el plot del entrenamiento.\n","  * el loss y el accuracy de train y validación en un csv.\n","\n","* Crea una condición de detención temprana, en la que si durante 3 épocas consecutivas no mejora 0,005 el modelo (utilizando el loss) pare el entrenamiento.\n","* lr = 0.001\n","* Número de épocas = 5\n","* Optimizador = Adam"],"metadata":{"id":"TK3tQAQof7LW"}},{"cell_type":"code","source":["model = MLP_pytorch().to(device)\n","epochs = 5\n","learning_rate = 0.001\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","path = ### CÓDIGO ###\n","\n","# EarlyStopping\n","val_loss_history = []\n","patience = 3\n","min_delta = 0.005\n","early_stop_counter = 0\n","\n","# Training progress Visualization\n","plot_namefile = \"training_plot.pdf\"\n","plot_path = path+plot_namefile\n","train_loss_history = []\n","train_acc_history = []\n","val_acc_history = []\n","\n","# Save results as csv\n","csv_file = \"training_results.csv\"\n","csv_path = path+csv_file\n","\n","# Model checkpoint\n","best_model_namefile = \"best_model.pth\"\n","best_model_path = path+best_model_namefile\n","\n","checkpoint_namefile = \"checkpoint.pth\"\n","checkpoint_path = path+checkpoint_namefile\n","best_val_loss = float('inf')"],"metadata":{"id":"Tx1U4i3Q-aTu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bucle de entrenamiento"],"metadata":{"id":"gUxGl4v7hOaH"}},{"cell_type":"code","source":["for epoch in range(epochs):\n","\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_loader:\n","\n","### CÓDIGO ###\n","\n","    with torch.no_grad():\n","\n","### CÓDIGO ###\n","\n","    print(f\"Época {epoch+1}/{epochs} | \"\n","          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n","          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","\n","    if val_loss < best_val_loss:\n","\n","### CÓDIGO ###\n","\n","    plot_progress(### CÓDIGO ###)\n","\n","    save_results(### CÓDIGO ###)\n","\n","    if epoch >= 1: # Early Stopping\n","      ### CÓDIGO ###"],"metadata":{"id":"mCMLhK0lwPB6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Cargar el modelo y el checkpoint"],"metadata":{"id":"81oHpWUthQrB"}},{"cell_type":"code","source":["model_complete = ### CÓDIGO ###"],"metadata":{"id":"PdVxhGc3Ew9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Usa el mismo optimizador\n","\n","# Cargar el checkpoint\n","checkpoint = torch.load(checkpoint_path)\n","model_complete.load_state_dict(### CÓDIGO ###)\n","optimizer.load_state_dict(### CÓDIGO ###)\n","epoch = ### CÓDIGO ###\n","loss = ### CÓDIGO ###"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhpGhBDOKukU","executionInfo":{"status":"ok","timestamp":1732995311855,"user_tz":-60,"elapsed":3,"user":{"displayName":"helena liz","userId":"14461101084112642621"}},"outputId":"da67fcf9-3897-433d-c42d-94f661d9aa05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-a5648f62d148>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path)\n"]}]},{"cell_type":"markdown","source":["## 8. Reentrenar el modelo\n","\n","Reentrenar durante 20 épocas, con las mismas condiciones que en el primer entrenamiento."],"metadata":{"id":"k6TMp5HJhWSw"}},{"cell_type":"code","source":["epochs = 20\n","path = ### CÓDIGO ###\n","model = model_complete\n","\n","\n","# EarlyStopping\n","val_loss_history = []\n","patience = 3\n","min_delta = 0.005\n","early_stop_counter = 0\n","\n","# Training progress Visualization\n","plot_namefile = \"training_plot.pdf\"\n","plot_path = path+plot_namefile\n","train_loss_history = []\n","train_acc_history = []\n","val_acc_history = []\n","\n","# Save results as csv\n","csv_file = \"training_results.csv\"\n","csv_path = path+csv_file\n","\n","# Model checkpoint\n","best_model_namefile = \"best_model.pth\"\n","best_model_path = path+best_model_namefile\n","\n","checkpoint_namefile = \"checkpoint.pth\"\n","checkpoint_path = path+checkpoint_namefile\n","best_val_loss = float('inf')"],"metadata":{"id":"fRXPhunLK2Qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### CÓDIGO ###"],"metadata":{"id":"N_DOWhdvLBwK","executionInfo":{"status":"ok","timestamp":1732998210164,"user_tz":-60,"elapsed":247,"user":{"displayName":"helena liz","userId":"14461101084112642621"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## 9. Evaluar el modelo con el conjunto de Test.\n","\n","Calcular el loss y el accuracy.\n","Guardar en listas:\n","* Etiquetas\n","* Predicciones\n","* Probabilidades"],"metadata":{"id":"z6TosV8zhftI"}},{"cell_type":"code","source":["model.eval()\n","\n","# Evaluación del modelo\n","total_loss = 0.0\n","correct = 0\n","total = 0\n","\n","all_labels = []\n","all_predictions = []\n","all_probabilities = []\n","\n","\n","with torch.no_grad():  # No calcular gradientes\n","    for inputs, labels in test_loader:\n","\n","        ### CÓDIGO ###\n","\n","        probabilities = torch.softmax(outputs, dim=1)  # Obtener probabilidades\n","        _, predicted = ### CÓDIGO ###\n","\n","### CÓDIGO ###\n","\n","print(f\"Pérdida promedio en test: {avg_loss:.4f}\")\n","print(f\"Precisión en test: {accuracy:.4%}\")\n","all_labels = np.array(all_labels)\n","all_predictions = np.array(all_predictions)\n","all_probabilities = np.array(all_probabilities)"],"metadata":{"id":"WD_gXuOOwMS_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. Inferencia\n","\n","Muestra las predicciones para 5 muestras para cada bach, durante 6 iteraciones.\n","\n","Tener en cuenta que tendréis que modificar la forma de las muestras."],"metadata":{"id":"JR5MnyfNh4mH"}},{"cell_type":"code","source":["image_shape = (150, 150)\n","\n","model.eval()\n","with torch.no_grad():\n","    for j, (inputs, labels) in enumerate(test_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","\n","        total_loss += loss.item()\n","\n","\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","        fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n","        for i, (img, pred, target) in enumerate(zip(inputs, predicted, labels)):\n","            if i >= 5:\n","                break\n","\n","### CÓDIGO ###\n","\n","        if j == 6:\n","          break"],"metadata":{"id":"n-68jed6wJJV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 11. Visualizaciones"],"metadata":{"id":"o-L9tr6LiPio"}},{"cell_type":"markdown","source":["### Reporte de clasificación de Sklearn"],"metadata":{"id":"a7crS6dLiXe0"}},{"cell_type":"code","source":["print(\"Reporte de Clasificación:\\n\")\n","### CÓDIGO ###"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUJJVfwBcbf3","executionInfo":{"status":"ok","timestamp":1732998349022,"user_tz":-60,"elapsed":225,"user":{"displayName":"helena liz","userId":"14461101084112642621"}},"outputId":"35a8af48-64cb-4cba-f6a3-38fb5ec0316e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Reporte de Clasificación:\n","\n"]}]},{"cell_type":"markdown","source":["### Matriz de confusión"],"metadata":{"id":"wFQGmKkFibO0"}},{"cell_type":"code","source":["### CÓDIGO ###"],"metadata":{"id":"KjubdNXAdSGL","executionInfo":{"status":"ok","timestamp":1732998347078,"user_tz":-60,"elapsed":193,"user":{"displayName":"helena liz","userId":"14461101084112642621"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Curva Roc global"],"metadata":{"id":"gCgpfzinidUr"}},{"cell_type":"code","source":["classes = np.unique(all_labels)\n","y_true_bin = label_binarize(all_labels, classes=classes)\n","\n","fpr = {}\n","tpr = {}\n","roc_auc = {}"],"metadata":{"id":"6UDXUBdawGDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### CÓDIGO ###"],"metadata":{"id":"Mo3bPR11dZ3O","executionInfo":{"status":"ok","timestamp":1732998358980,"user_tz":-60,"elapsed":189,"user":{"displayName":"helena liz","userId":"14461101084112642621"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Curva Roc por clases"],"metadata":{"id":"1rDKLkB3iiyW"}},{"cell_type":"code","source":["### CÓDIGO ###"],"metadata":{"id":"1Z59Bsc3diBe","executionInfo":{"status":"ok","timestamp":1732998340386,"user_tz":-60,"elapsed":215,"user":{"displayName":"helena liz","userId":"14461101084112642621"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"loBTmQocdl7t"},"execution_count":null,"outputs":[]}]}